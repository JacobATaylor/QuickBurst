{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa22a4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20760/956813560.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:99% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:99% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9894cd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: version mismatch between CFITSIO header (v4.000999999999999) and linked library (v4.01).\n",
      "\n",
      "\n",
      "WARNING: version mismatch between CFITSIO header (v4.000999999999999) and linked library (v4.01).\n",
      "\n",
      "\n",
      "WARNING: version mismatch between CFITSIO header (v4.000999999999999) and linked library (v4.01).\n",
      "\n",
      "WARNING: AstropyDeprecationWarning: The private astropy._erfa module has been made into its own package, pyerfa, which is a dependency of astropy and can be imported directly using \"import erfa\" [astropy._erfa]\n"
     ]
    }
   ],
   "source": [
    "#chack for updated files\\n,\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#import packages\n",
    "from __future__ import division\n",
    "\n",
    "%load_ext line_profiler\n",
    "import numpy as np\n",
    "import glob, json\n",
    "import pickle\n",
    "import os as os_pack\n",
    "import matplotlib.pyplot as plt\n",
    "import corner\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import healpy as hp\n",
    "import os, glob, json, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.linalg as sl\n",
    "import enterprise\n",
    "from enterprise.pulsar import Pulsar\n",
    "import enterprise.signals.parameter as parameter\n",
    "from enterprise.signals import utils\n",
    "from enterprise.signals import signal_base\n",
    "from enterprise.signals import selections\n",
    "from enterprise.signals.selections import Selection\n",
    "from enterprise.signals import white_signals\n",
    "from enterprise.signals import gp_signals\n",
    "from enterprise.signals import deterministic_signals\n",
    "import enterprise.constants as const\n",
    "from enterprise_extensions import blocks\n",
    "from enterprise_extensions import models as ee_models\n",
    "from enterprise_extensions import model_utils as ee_model_utils\n",
    "from enterprise_extensions import model_orfs\n",
    "from enterprise_extensions.hypermodel import HyperModel\n",
    "from enterprise_extensions.frequentist import optimal_statistic as opt_stat\n",
    "from enterprise_extensions import sampler as ee_sampler\n",
    "from enterprise.signals.signal_base import LogLikelihood\n",
    "#import enterprise_wavelets as models\n",
    "from enterprise.signals.deterministic_signals import Deterministic\n",
    "from enterprise.signals.parameter import function\n",
    "from la_forge.core import Core\n",
    "from la_forge.diagnostics import plot_chains\n",
    "from la_forge import rednoise\n",
    "import la_forge\n",
    "import corner\n",
    "from PTMCMCSampler.PTMCMCSampler import PTSampler as ptmcmc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d45a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def figsize(scale):\n",
    "    fig_width_pt = 513.17 #469.755                  # Get this from LaTeX using \\the\\textwidth\n",
    "    inches_per_pt = 1.0/72.27                       # Convert pt to inch\n",
    "    golden_mean = (np.sqrt(5.0)-1.0)/2.0            # Aesthetic ratio (you could change this)\n",
    "    fig_width = fig_width_pt*inches_per_pt*scale    # width in inches\n",
    "    fig_height = fig_width*golden_mean              # height in inches\n",
    "    fig_size = [2 * fig_width,2 * fig_height]       #1* scaling factor for 2 collem paper\n",
    "    return fig_size\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "params = {'backend': 'pdf',\n",
    "        'axes.labelsize': 18,\n",
    "        'lines.markersize': 4,\n",
    "        'font.size': 12,\n",
    "        'xtick.major.size':6,\n",
    "        'xtick.minor.size':3,  \n",
    "        'ytick.major.size':6,\n",
    "        'ytick.minor.size':3, \n",
    "        'xtick.major.width':0.5,\n",
    "        'ytick.major.width':0.5,\n",
    "        'xtick.minor.width':0.5,\n",
    "        'ytick.minor.width':0.5,\n",
    "        'lines.markeredgewidth':1,\n",
    "        'axes.linewidth':1.2,\n",
    "        'legend.fontsize': 13,\n",
    "        'xtick.labelsize': 14,\n",
    "        'ytick.labelsize': 14,\n",
    "        'savefig.dpi':200,\n",
    "        'path.simplify':True,\n",
    "        'font.family': 'serif',\n",
    "        #'font.serif':'Times',\n",
    "        #'text.latex.preamble': [r'\\usepackage{amsmath}'],\n",
    "        #'text.usetex':True,\n",
    "        'figure.figsize': figsize(0.5)}\n",
    "#plt.style.use('dark_background')\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bc1cd8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dataset w/out RN w/ parabolic encounter @ 30 Mpc\n",
    "# with open(\"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Data/Paper_Datasets/30Mpc_parabolic_flyby/noRN/Psrs_pkl_10yrs.pkl\", 'rb') as f:\n",
    "#     psrs_sim = pickle.load(f)\n",
    "\n",
    "#Dataset w/ RN w/ parabolic encounter @ 60 Mpc\n",
    "# with open(\"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Data/Paper_Datasets/60Mpc_parabolic_flyby/RN/Psrs_pkl_10yrs.pkl\", 'rb') as f:\n",
    "#     psrs_sim = pickle.load(f)\n",
    "\n",
    "with open(\"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Data/Paper_Datasets/Simple_20Psr_30Mpc_parabolic_flyby/noCURN/Psrs_pkl.pkl\", 'rb') as f:\n",
    "    psrs_sim = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f40ec642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(psrs_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c20d9dde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JPSR00_efac': 1.0,\n",
       " 'JPSR01_efac': 1.0,\n",
       " 'JPSR02_efac': 1.0,\n",
       " 'JPSR03_efac': 1.0,\n",
       " 'JPSR04_efac': 1.0,\n",
       " 'JPSR05_efac': 1.0,\n",
       " 'JPSR06_efac': 1.0,\n",
       " 'JPSR07_efac': 1.0,\n",
       " 'JPSR08_efac': 1.0,\n",
       " 'JPSR09_efac': 1.0,\n",
       " 'JPSR10_efac': 1.0,\n",
       " 'JPSR11_efac': 1.0,\n",
       " 'JPSR12_efac': 1.0,\n",
       " 'JPSR13_efac': 1.0,\n",
       " 'JPSR14_efac': 1.0,\n",
       " 'JPSR15_efac': 1.0,\n",
       " 'JPSR16_efac': 1.0,\n",
       " 'JPSR17_efac': 1.0,\n",
       " 'JPSR18_efac': 1.0,\n",
       " 'JPSR19_efac': 1.0,\n",
       " 'JPSR00_log10_equad': -17,\n",
       " 'JPSR01_log10_equad': -17,\n",
       " 'JPSR02_log10_equad': -17,\n",
       " 'JPSR03_log10_equad': -17,\n",
       " 'JPSR04_log10_equad': -17,\n",
       " 'JPSR05_log10_equad': -17,\n",
       " 'JPSR06_log10_equad': -17,\n",
       " 'JPSR07_log10_equad': -17,\n",
       " 'JPSR08_log10_equad': -17,\n",
       " 'JPSR09_log10_equad': -17,\n",
       " 'JPSR10_log10_equad': -17,\n",
       " 'JPSR11_log10_equad': -17,\n",
       " 'JPSR12_log10_equad': -17,\n",
       " 'JPSR13_log10_equad': -17,\n",
       " 'JPSR14_log10_equad': -17,\n",
       " 'JPSR15_log10_equad': -17,\n",
       " 'JPSR16_log10_equad': -17,\n",
       " 'JPSR17_log10_equad': -17,\n",
       " 'JPSR18_log10_equad': -17,\n",
       " 'JPSR19_log10_equad': -17}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading in pickle and noise files\n",
    "#15 year A4Cast noise file\n",
    "# noise_file_sim = \"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Data/quickburst_test_15yrAstro4Cast_parabolic_3Mpc_60M/v1p1_all_dict.json\"\n",
    "\n",
    "#Simple 20PSR CURN dataset noise file\n",
    "noise_file_sim = \"/home/reyna/BayesHopperBurst/BenceData/with_burst/params_simulated.json\"\n",
    "with open(noise_file_sim, 'rb') as h:\n",
    "    noise_params = json.load(h)\n",
    "noise_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db38b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove nmodel from noise_params\n",
    "#del noise_params['nmodel']\n",
    "#Injected CURN parameter values for 15 year 3Mpc 60Msolar parabolic flyby \n",
    "Amp = -14.22 #-14.6 #-16.27\n",
    "gamma = 13/3 #6.6\n",
    "\n",
    "noise_params['gw_crn_gamma'] = gamma\n",
    "noise_params['gw_crn_log10_A'] = Amp\n",
    "\n",
    "noise_dict_sim = {} #new noise dict to conver the simulated noise file into a readable formate\n",
    "for k,v in noise_params.items():\n",
    "    if '_equad' in k:\n",
    "        noise_dict_sim.update({k.split('_equad')[0] + '_t2equad': v})\n",
    "    else:\n",
    "        noise_dict_sim.update({k : v})\n",
    "noise_params = noise_dict_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a84b97f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JPSR00_efac': 1.0,\n",
       " 'JPSR01_efac': 1.0,\n",
       " 'JPSR02_efac': 1.0,\n",
       " 'JPSR03_efac': 1.0,\n",
       " 'JPSR04_efac': 1.0,\n",
       " 'JPSR05_efac': 1.0,\n",
       " 'JPSR06_efac': 1.0,\n",
       " 'JPSR07_efac': 1.0,\n",
       " 'JPSR08_efac': 1.0,\n",
       " 'JPSR09_efac': 1.0,\n",
       " 'JPSR10_efac': 1.0,\n",
       " 'JPSR11_efac': 1.0,\n",
       " 'JPSR12_efac': 1.0,\n",
       " 'JPSR13_efac': 1.0,\n",
       " 'JPSR14_efac': 1.0,\n",
       " 'JPSR15_efac': 1.0,\n",
       " 'JPSR16_efac': 1.0,\n",
       " 'JPSR17_efac': 1.0,\n",
       " 'JPSR18_efac': 1.0,\n",
       " 'JPSR19_efac': 1.0,\n",
       " 'JPSR00_log10_t2equad': -17,\n",
       " 'JPSR01_log10_t2equad': -17,\n",
       " 'JPSR02_log10_t2equad': -17,\n",
       " 'JPSR03_log10_t2equad': -17,\n",
       " 'JPSR04_log10_t2equad': -17,\n",
       " 'JPSR05_log10_t2equad': -17,\n",
       " 'JPSR06_log10_t2equad': -17,\n",
       " 'JPSR07_log10_t2equad': -17,\n",
       " 'JPSR08_log10_t2equad': -17,\n",
       " 'JPSR09_log10_t2equad': -17,\n",
       " 'JPSR10_log10_t2equad': -17,\n",
       " 'JPSR11_log10_t2equad': -17,\n",
       " 'JPSR12_log10_t2equad': -17,\n",
       " 'JPSR13_log10_t2equad': -17,\n",
       " 'JPSR14_log10_t2equad': -17,\n",
       " 'JPSR15_log10_t2equad': -17,\n",
       " 'JPSR16_log10_t2equad': -17,\n",
       " 'JPSR17_log10_t2equad': -17,\n",
       " 'JPSR18_log10_t2equad': -17,\n",
       " 'JPSR19_log10_t2equad': -17,\n",
       " 'gw_crn_gamma': 4.333333333333333,\n",
       " 'gw_crn_log10_A': -14.22}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee5140fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145.2054684686619\n",
      "9.945234130667286\n"
     ]
    }
   ],
   "source": [
    "#Setting dataset max time and reference time\n",
    "maximum = 0\n",
    "minimum = np.inf\n",
    "for psr in psrs_sim:\n",
    "    if psr.toas.max() > maximum:\n",
    "        maximum = psr.toas.max()\n",
    "    if psr.toas.min() < minimum:\n",
    "        minimum = psr.toas.min()\n",
    "\n",
    "\n",
    "#Sets reference time\n",
    "tref = minimum\n",
    "print(tref/3600/24/365)\n",
    "t0_max = (maximum - minimum)/365/24/3600\n",
    "print(t0_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108c98a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/reyna/BayesHopperBurst/QuickBurst/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mQuickBurst_MCMC_testing\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mQuickBurst_MCMC\u001b[39;00m\n\u001b[1;32m      3\u001b[0m N_slow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1e5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/reyna/BayesHopperBurst/QuickBurst/')\n",
    "import QuickBurst_MCMC_testing as QuickBurst_MCMC\n",
    "N_slow=int(1e5)\n",
    "n_fish_update = int(N_slow/2)\n",
    "\n",
    "T_max = 4 #2\n",
    "n_chain = 5 #3\n",
    "\n",
    "#Prior bounds on shape params\n",
    "tau_min = 0.2\n",
    "tau_max = 3.0 #5.0\n",
    "f_max = 1e-7\n",
    "f_min = 1e-8 #3.5e-9\n",
    "\n",
    "#Simple 30Mpc dataset\n",
    "ts_file = \"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Data/Paper_Datasets/Simple_20Psr_30Mpc_parabolic_flyby/CURN_13_3/simple_wavelet_tau_scan_tau_max_3yr.pkl\"\n",
    "glitch_ts_file = \"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Data/Paper_Datasets/Simple_20Psr_30Mpc_parabolic_flyby/CURN_13_3/simple_glitch_tau_scan_tau_max_3yr.pkl\"\n",
    "\n",
    "\n",
    "#30 Mpc dataset\n",
    "# ts_file = \"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Data/Paper_Datasets/30Mpc_parabolic_flyby/noRN/wavelet_tauscan_15yr-Astro4Cast_parabolic_30Mpc_NoRN.pkl\"\n",
    "# glitch_ts_file = \"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Data/Paper_Datasets/30Mpc_parabolic_flyby/noRN/glitch_tauscan_15yr-Astro4Cast_parabolic_30Mpc_NoRN.pkl\"\n",
    "\n",
    "#60Mpc dataaset\n",
    "# ts_file = \"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Data/Paper_Datasets/60Mpc_parabolic_flyby/RN/10yrs_psrs_tauscans/wavelet_tauscan_fixed_NaNs.pkl\"\n",
    "# glitch_ts_file = \"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Data/Paper_Datasets/60Mpc_parabolic_flyby/RN/10yrs_psrs_tauscans/glitch_tauscan_fixed_NaNs.pkl\"\n",
    "\n",
    "#noisedict_file = \"/home/reyna/BayesHopperBurst/BenceData/with_burst/params_simulated.json\"\n",
    "#RN_start_file = \"../12p5yr-like_data/RN_start_values.npz\"\n",
    "\n",
    "#start_file = \"/home/reyna/BayesHopperBurst/QuickBurst/Testing/2_wavelet_sim/chain_QB2.npz\"\n",
    "filepath = \"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Chains/QuickBurst/Paper_chains/Simple_20PSR_30Mpc_parabolic_flyby/CURN_13_3/Enterprise_comparison/\"\n",
    "os.makedirs(filepath, exist_ok = True)\n",
    "savepath = filepath + \"5w3g_4maxTemp_Tau3yr_Alljumps\" #only saving a chain\n",
    "\n",
    "attributes = ['resres_logdet', 'glitch_prm', 'wavelet_prm', 'glitch_pulsars', 'params', 'NN', 'sigmas'] #'Nvecs_previous', 'Nvecs', 'MMs',\n",
    "#step_array, likelihood_attributes\n",
    "samples, acc_fraction, swap_record, rj_record, ptas, ent_ptas, log_likelihood, ent_lnlikelihood, betas, PT_acc = QuickBurst_MCMC.run_bhb(N_slow, T_max, n_chain, psrs_sim,\n",
    "                                                                    max_n_wavelet=5,\n",
    "                                                                    min_n_wavelet=0,\n",
    "                                                                    n_wavelet_start=2,\n",
    "                                                                    RJ_weight=2,\n",
    "                                                                    glitch_RJ_weight=2,\n",
    "                                                                    regular_weight=2,\n",
    "                                                                    noise_jump_weight=2,\n",
    "                                                                    PT_swap_weight=2,\n",
    "                                                                    tau_scan_proposal_weight=2,\n",
    "                                                                    glitch_tau_scan_proposal_weight=2,\n",
    "                                                                    tau_scan_file=ts_file,\n",
    "                                                                    glitch_tau_scan_file=glitch_ts_file,\n",
    "                                                                    #gwb_log_amp_range=[-18,-15],\n",
    "                                                                    rn_log_amp_range=[-18,-15],\n",
    "                                                                    wavelet_log_amp_range=[-10.0,-5.8],\n",
    "                                                                    per_psr_rn_log_amp_range=[-18,-11],\n",
    "                                                                    #rn_params = [noise_params['gw_crn_log10_A'],noise_params['gw_crn_gamma']],\n",
    "                                                                    prior_recovery=False,\n",
    "                                                                    #gwb_amp_prior='log-uniform',\n",
    "                                                                    rn_amp_prior='log-uniform',\n",
    "                                                                    wavelet_amp_prior='uniform',\n",
    "                                                                    per_psr_rn_amp_prior='log-uniform',\n",
    "                                                                    #gwb_on_prior=0.975,\n",
    "                                                                    max_n_glitch=3,\n",
    "                                                                    #n_glitch_start='random',\n",
    "                                                                    glitch_log_amp_range=[-10.0,-5.8],\n",
    "                                                                    glitch_amp_prior='uniform',\n",
    "                                                                    f0_max = f_max,\n",
    "                                                                    f0_min = f_min,\n",
    "                                                                    tau_max_in = tau_max,\n",
    "                                                                    tau_min_in = tau_min,\n",
    "                                                                    t0_max=t0_max,\n",
    "                                                                    tref = tref,\n",
    "                                                                    vary_white_noise=True,  \n",
    "                                                                    include_rn=True, vary_rn=True,\n",
    "                                                                    include_equad=True,\n",
    "                                                                    include_ecorr=False,\n",
    "                                                                    include_efac=True,\n",
    "                                                                    wn_backend_selection=False,\n",
    "                                                                    noisedict= noise_params,\n",
    "                                                                    include_per_psr_rn=False,\n",
    "                                                                    vary_per_psr_rn=False,\n",
    "                                                                    #resume_from=savepath,\n",
    "                                                                    #per_psr_rn_start_file=RN_start_file,\n",
    "                                                                    n_fish_update = n_fish_update,\n",
    "                                                                    savepath=savepath, save_every_n=100,\n",
    "                                                                    n_fast_to_slow=1, thin = 100, ent_lnlike_test = True, ent_verbosity = True, QB_attributes = attributes)\n",
    "                         \n",
    "#np.savez(savefile, samples=samples, acc_fraction=acc_fraction, swap_record=swap_record, log_likelihood=log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f17bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_array[701]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(step_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6cae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chain = [n for n in range(len(acc_fraction[6]))]\n",
    "print(n_chain)\n",
    "for n in n_chain: \n",
    "    plt.figure(figsize = (7,5))\n",
    "    plt.plot(ent_lnlikelihood[n], ent_lnlikelihood[n], ls='--', marker='.', color='xkcd:blue', label = 'Ent')\n",
    "    plt.plot(ent_lnlikelihood[n], log_likelihood[n], ls='', marker='.', color='xkcd:green', label = 'FastB')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel(\"Enterprise LogL\")\n",
    "    plt.ylabel(\"QB LogL\")\n",
    "    plt.title('QuickBurst MCMC likelihood comparisons: chain {}'.format(n))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f24150",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(step_array[1000*10-9])\n",
    "log_likelihood[0][100:] - ent_lnlikelihood[0][100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613eef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in n_chain:\n",
    "    plt.figure(figsize = (7,5))\n",
    "    plt.plot(log_likelihood[n][:] - ent_lnlikelihood[n][:], ls='', marker='.', color='xkcd:blue')\n",
    "    #plt.gca().axhline(0.1, ls='--', color='xkcd:green')\n",
    "    plt.xlabel(\"index\")\n",
    "    plt.ylabel(\"delta log(likelihood)\")\n",
    "    #plt.ylim()\n",
    "    plt.title('Difference in QB MCMC samples: chain {}'.format(n))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eeb1f3",
   "metadata": {},
   "source": [
    "## Run this to check steps for likelihoods that didn't match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe76a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in n_chain:\n",
    "    for i inn range(len(log_likelihood[0])):\n",
    "        if log_likelihood[n][i] - ent_lnlikelihood[n][i] > 1e-9 or log_likelihood[n][i] - ent_lnlikelihood[n][i] < -1e-9:\n",
    "            print(step_array[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd5243",
   "metadata": {},
   "source": [
    "### 9/16/23 Well, something is broken again, so we will have to return to troubleshooting techniques again. I've re-added in calculating enterprise likelihoods, and it's fairly stable for at least potentially 1e3 samples (though I only did 1e2 to preserve another timing run for the MCMC. \n",
    "### I THINK we can probably still use the timing data despite this, but depending on what broke, that data may change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd638d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_iter = 0\n",
    "stop_iter = 10\n",
    "\n",
    "# for i in range(start_iter, stop_iter-1):\n",
    "#     print(i)\n",
    "print(max(range(start_iter, stop_iter-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da07068",
   "metadata": {},
   "source": [
    "# Running samples through enterprise PTAs to test for agreement\n",
    "## Note: Can also do this by loading in chain and calling QuickBurst.get_pta() and simply returning the enterprise ptas. The parameter volume in get_pta() must match the run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5737c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "filename = \"/home/reyna/BayesHopperBurst/QuickBurst/12p5_year_A4Cast/chains/12p5yr_A4Cast_1g1w_noWN_speedups_enterprisetest.h5df\"\n",
    "\n",
    "with h5py.File(filename, 'r+') as f:\n",
    "    n_chain = 2\n",
    "    samples_array = f['samples_cold'][()]\n",
    "    log_likelihood = f['log_likelihood'][()]\n",
    "    #ent_lnlikelihood = f['ent_lnlikelihood'][()]\n",
    "    acc_frac = f['acc_fraction'][()]\n",
    "    param_names = f['par_names'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13503242",
   "metadata": {},
   "outputs": [],
   "source": [
    "globvar = True\n",
    "\n",
    "\n",
    "def print_globvar():\n",
    "    print(globvar)\n",
    "print_globvar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff21ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ent_ptas[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_glitch=1\n",
    "max_n_wavelet=1\n",
    "for i in range(max_n_wavelet+1):\n",
    "    for j in range(max_n_glitch+1):\n",
    "        with open(\"/home/reyna/BayesHopperBurst/QuickBurst/12p5_year_A4Cast/ent_ptas_test/{}w{}g_noWN_ent_ptas.json\".format(i, j), \"wb\") as f:\n",
    "                json.dump(ent_ptas[i][j], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0210e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "n_chain = len(samples_array[0])\n",
    "num_samples = len(samples_array[0, :, 0])\n",
    "print('chain length: {}'.format(num_samples))\n",
    "ent_lnlikelihoods = []\n",
    "#loop through number of samples\n",
    "starting_time = time.time()\n",
    "for i in range(num_samples):\n",
    "    if i%num_samples/10 or i == 0:\n",
    "        print('Currently at {}% in {} seconds'.format(int(i/num_samples)*100, starting_time-time.time()))\n",
    "    temp_lnlikelihoods = []\n",
    "    for j in range(n_chain):\n",
    "        n_wavelet = int(samples_array[j, i, 0])\n",
    "        n_glitch = int(samples_array[j, i, 1])\n",
    "        x0 = samples_array[j, i, 2:]\n",
    "        print(n_wavelet, n_glitch, x0)\n",
    "        print(ent_ptas[n_wavelet][n_glitch], '\\n', ent_ptas[n_wavelet][n_glitch].params)\n",
    "        temp_lnlikelihoods.append(ent_ptas[n_wavelet][n_glitch].get_lnlikelihood(x0))\n",
    "    ent_lnlikelihoods.append(temp_lnlikelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccca21c8",
   "metadata": {},
   "source": [
    "## Take differences of likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f12f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "like_diff = []\n",
    "for i in range(num_samples):\n",
    "    temp_diffs = []\n",
    "    for j in range(n_chain):\n",
    "        temp_diffs.append(log_likelihood[j, i] - ent_lnlikelihoods[j, i])\n",
    "    like_diff.append(temp_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "like_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a14816",
   "metadata": {},
   "source": [
    "# Testing for ShermanMorrison stuff below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e5e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_wavelet = 5\n",
    "max_n_glitch = 5\n",
    "n_wavelet_start = 1\n",
    "n_glitch_start = 1\n",
    "save_every_n = 100\n",
    "num_params = max_n_wavelet*10+max_n_glitch*6\n",
    "num_params += 2 #for keepeng a record of number of wavelets and glitches\n",
    "\n",
    "vary_rn = True\n",
    "vary_per_psr_rn = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bcd6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dict_sim = {} #new noise dict to conver the simulated noise file into a readable formate\n",
    "for k,v in noise_params_sim.items():\n",
    "    if '_equad' in k:\n",
    "        noise_dict_sim.update({k.split('_equad')[0] + '_t2equad': v})\n",
    "    else:\n",
    "        noise_dict_sim.update({k : v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c28e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dict_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faabc8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import QuickBurst_MCMC\n",
    "\n",
    "PTA, ent_ptas, QB_FP, QB_FPI, glitch_indx, wavelet_indx, per_puls_wn_indx, per_puls_rn_indx, rn_indx, num_per_puls_wn_param_list = QuickBurst_MCMC.get_pta(psrs_sim, \n",
    "                                                                                                            vary_white_noise = False,\n",
    "                                                                                                            max_n_wavelet=max_n_wavelet, \n",
    "                                                                                                            max_n_glitch=max_n_glitch,   \n",
    "                                                                                                            include_equad = True, \n",
    "                                                                                                            include_ecorr = True, \n",
    "                                                                                                            wn_backend_selection=True, \n",
    "                                                                                                            noisedict=noise_dict_sim, \n",
    "                                                                                                            include_rn=True, \n",
    "                                                                                                            vary_rn=vary_rn, \n",
    "                                                                                                            include_per_psr_rn=True, \n",
    "                                                                                                            vary_per_psr_rn=vary_per_psr_rn, t0_max = t0_max, tref = tref) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2082a37e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197379fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_per_psr_wn_params = 0\n",
    "num_per_psr_rn_params = 0\n",
    "num_noise_params = 0\n",
    "#total # of wn params in pta\n",
    "num_per_psr_wn_params += sum(num_per_puls_wn_param_list)\n",
    "\n",
    "#CURN A and gamma\n",
    "if vary_rn:\n",
    "    num_noise_params += 2\n",
    "if vary_per_psr_rn:\n",
    "    #A and gamma per pulsar\n",
    "    num_per_psr_rn_params += 2*len(psrs_sim)\n",
    "\n",
    "#Total # of noise params\n",
    "num_noise_params += num_per_psr_rn_params + num_per_psr_wn_params\n",
    "\n",
    "#Total num params: per_puls_wn + per_puls_rn + CURN + wave/glitch\n",
    "num_params += num_noise_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77046b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bbef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.zeros((1, save_every_n+1, num_params))\n",
    "\n",
    "print(np.shape(samples))\n",
    "samples[0,0,0] = n_wavelet_start\n",
    "samples[0,0,1] = n_glitch_start\n",
    "samples[0,0,2:] =  np.hstack(p.sample() for p in PTA.params)\n",
    "\n",
    "for param, idx in enumerate(PTA.param_names):\n",
    "    if param in noise_dict_sim.keys():\n",
    "        samples[j, 0, 2+idx] = noise_dict_sim[param]\n",
    "        \n",
    "for windx in range(max_n_wavelet):\n",
    "    samples[0,0,2+int(wavelet_indx[windx,0])] = samples[0,0,2+int(wavelet_indx[0,0])]\n",
    "    samples[0,0,2+int(wavelet_indx[windx,1])] = samples[0,0,2+int(wavelet_indx[0,1])]\n",
    "    samples[0,0,2+int(wavelet_indx[windx,2])] = samples[0,0,2+int(wavelet_indx[0,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f960d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(PTA.signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cbe145",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_wavelet = int(samples[0,0,0])\n",
    "n_glitch = int(samples[0,0,1])\n",
    "first_sample = np.copy(samples[0,0,2:])\n",
    "\n",
    "#Generate first sample param dictionary\n",
    "param_names = PTA.param_names\n",
    "sample_dict = dict((k, v) for k, v in zip(param_names, first_sample))\n",
    "# for i in range(len(first_sample)):\n",
    "#     sample_dict[PTA.param_names[i]] = first_sample[i]\n",
    "rn_check = False\n",
    "\n",
    "if vary_per_psr_rn or vary_rn:\n",
    "    rn_check = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b8b6a",
   "metadata": {},
   "source": [
    "## Let's check the parameter types in QuickBurst using EcorrBasisModel for ecorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb102a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8501b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = PTA.param_names[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf20d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = dict((k, v) for k, v in zip(param_names, num_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_time = time.time()\n",
    "param_names = PTA.param_names[0:40]\n",
    "numberrr = 40\n",
    "num_list = [x for x in range(numberrr)]\n",
    "test_dict = dict((k, v) for k, v in zip(param_names, num_list))\n",
    "print('time to make dict: ', time.time()-starting_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f44e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_time = time.time()\n",
    "param_names = PTA.param_names[0:40]\n",
    "num_list = [x for x in range(numberrr)]\n",
    "d0 = {}\n",
    "for i in range(len(num_list)):\n",
    "    d0[PTA.param_names[i]] = num_list[i]\n",
    "print('time to make dict: ', time.time()-starting_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da758929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Nvecs = list(PTA.get_ndiag(sample_dict))\n",
    "TNTs = PTA.get_TNT(sample_dict)\n",
    "\n",
    "#important matrixies\n",
    "Nvecs = list(PTA.get_ndiag(sample_dict))\n",
    "TNTs = PTA.get_TNT(sample_dict)\n",
    "Ts = PTA.get_basis()\n",
    "\n",
    "#pulsar information\n",
    "toas = list([psr.toas - tref for psr in psrs_sim])\n",
    "residuals = list([psr.residuals for psr in psrs_sim])\n",
    "pos = np.zeros((len(psrs_sim),3))\n",
    "for i in range(len(psrs_sim)):\n",
    "    pos[i] = psrs_sim[i].pos\n",
    "\n",
    "    logdet = 0\n",
    "for (l,m) in PTA.get_rNr_logdet(sample_dict): #Only using this for logdet term because the rNr term removes the deterministic signal durring generation\n",
    "    logdet += m\n",
    "\n",
    "#terms used in cholesky component of the dot product (only needs to be updated per-pulsar)\n",
    "invCholSigmaTN = []\n",
    "phiinvs = PTA.get_phiinv(sample_dict, logdet=False, method='partition') #use enterprise to calculate phiinvs\n",
    "for ii in range(len(psrs_sim)):\n",
    "    TNT = TNTs[ii]\n",
    "    T = Ts[ii]\n",
    "    phiinv = phiinvs[ii]\n",
    "    #print('self.Nvecs[ii]', Nvecs[ii][0:1000])\n",
    "    Ndiag = 1/Nvecs[ii]\n",
    "    Sigma = TNT + (np.diag(phiinv) if phiinv.ndim == 1 else phiinv)\n",
    "    chol_Sigma,lower = sl.cho_factor(Sigma.T,lower=True,overwrite_a=True,check_finite=False)\n",
    "    invchol_Sigma_T_loc = solve_triangular(chol_Sigma,T.T,lower_a=True,trans_a=False,overwrite_b=False)\n",
    "    invCholSigmaTN.append(invchol_Sigma_T_loc)#*Ndiag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c4eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Nvecs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709efa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Nvecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588a7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(np.array(np.copy(a.data))))\n",
    "print(type(a.copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af1fc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, psr in enumerate(psrs_sim):\n",
    "    print(psr.name, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8795c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(Nvecs[20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f7bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
