{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d757235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4799/956813560.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:99% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:99% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45d59a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: The private astropy._erfa module has been made into its own package, pyerfa, which is a dependency of astropy and can be imported directly using \"import erfa\" [astropy._erfa]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "exec('from __future__ import division')\n",
    "\n",
    "import numpy as np\n",
    "import os, glob, json\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib import colors as mcolors\n",
    "from matplotlib.patches import Rectangle\n",
    "spec_colors = {\"data\": \"xkcd:blue\",\n",
    "               \"GW_rec\": \"xkcd:red\",\n",
    "               \"GW_inj\": \"xkcd:purple\",\n",
    "               \"glitch_rec\": \"xkcd:green\",\n",
    "               \"glitch_inj\": \"xkcd:olive\"}\n",
    "\n",
    "import scipy.linalg as sl\n",
    "\n",
    "import enterprise\n",
    "from enterprise.pulsar import Pulsar\n",
    "import enterprise.signals.parameter as parameter\n",
    "from enterprise.signals import utils\n",
    "from enterprise.signals import signal_base\n",
    "from enterprise.signals import selections\n",
    "from enterprise.signals.selections import Selection\n",
    "from enterprise.signals import white_signals\n",
    "from enterprise.signals import gp_signals\n",
    "from enterprise.signals import deterministic_signals\n",
    "import enterprise.constants as const\n",
    "import re\n",
    "\n",
    "import enterprise_extensions\n",
    "\n",
    "import corner\n",
    "\n",
    "import pickle\n",
    "import emcee\n",
    "\n",
    "import libstempo as T2\n",
    "import libstempo.toasim as LT\n",
    "import libstempo.plot as LP\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "import QuickBurst_MCMC as QB_mcmc\n",
    "\n",
    "from pylab import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe9e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def figsize(scale):\n",
    "    fig_width_pt = 513.17 #469.755                  # Get this from LaTeX using \\the\\textwidth\n",
    "    inches_per_pt = 1.0/72.27                       # Convert pt to inch\n",
    "    golden_mean = (np.sqrt(5.0)-1.0)/2.0            # Aesthetic ratio (you could change this)\n",
    "    fig_width = fig_width_pt*inches_per_pt*scale    # width in inches\n",
    "    fig_height = fig_width*golden_mean              # height in inches\n",
    "    fig_size = [2 * fig_width,2 * fig_height]       #1* scaling factor for 2 collem paper\n",
    "    return fig_size\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "params = {'backend': 'pdf',\n",
    "        'axes.labelsize': 18,\n",
    "        'lines.markersize': 4,\n",
    "        'font.size': 12,\n",
    "        'xtick.major.size':6,\n",
    "        'xtick.minor.size':3,  \n",
    "        'ytick.major.size':6,\n",
    "        'ytick.minor.size':3, \n",
    "        'xtick.major.width':0.5,\n",
    "        'ytick.major.width':0.5,\n",
    "        'xtick.minor.width':0.5,\n",
    "        'ytick.minor.width':0.5,\n",
    "        'lines.markeredgewidth':1,\n",
    "        'axes.linewidth':1.2,\n",
    "        'legend.fontsize': 13,\n",
    "        'xtick.labelsize': 14,\n",
    "        'ytick.labelsize': 14,\n",
    "        'savefig.dpi':200,\n",
    "        'path.simplify':True,\n",
    "        'font.family': 'serif',\n",
    "        #'font.serif':'Times',\n",
    "        #'text.latex.preamble': [r'\\usepackage{amsmath}'],\n",
    "        #'text.usetex':True,\n",
    "        'figure.figsize': figsize(0.5)}\n",
    "#plt.style.use('dark_background')\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e58bb6",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6624eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in pulsar pickle files\n",
    "with open( \"/home/user/path_to/.../data.pkl\", 'rb') as f:\n",
    "    psrs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79141f41",
   "metadata": {},
   "source": [
    "## Visualizing residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd131f21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, psr in enumerate(psrs):\n",
    "#     resids = psr.residuals()\n",
    "    plt.figure(i)      \n",
    "    plt.errorbar(psr.toas/86400,\n",
    "            psr.residuals,\n",
    "            yerr=psr.toaerrs,\n",
    "            markersize=8, ls='', marker='x', alpha=0.5)\n",
    "    plt.xlabel('Time [MJD]')\n",
    "    plt.ylabel(r'Residuals [$\\mu$s]')\n",
    "    plt.title('Pulsar {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0645fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "'''\n",
    "When loading file, can load the following chain properties: \n",
    "\n",
    "1) f['samples_cold'] -> Parameter samples for all chains\n",
    "2) f['log_likelihood'] -> Likelihoods for all chains\n",
    "3) f['acc_fraction'] -> acceptance fractions for all chains\n",
    "4) f['param_names'] -> Parameter names for all varied parameters in PTA model. Corresponds to output of pta.param_names().\n",
    "5) f['swap_record'] -> Record of chain swaps between all chains.\n",
    "6) f['betas'] -> Record of Temperature values in all chains (as 1/Ts). \n",
    "7) f['PT_acc'] -> Parallel tempering acceptance rates for all chains.\n",
    "\n",
    "'''\n",
    "\n",
    "filename = '/home/user/path_to/.../chain.h5df'\n",
    "with h5py.File(filename, 'r+') as f:\n",
    "    samples_array = f['samples_cold'][()]\n",
    "    log_likelihood = f['log_likelihood'][()]\n",
    "    acc_frac = f['acc_fraction'][()]\n",
    "    param_names = f['par_names'][()]\n",
    "\n",
    "print(acc_frac)\n",
    "#print(ent_lnlikelihood)\n",
    "samples = samples_array\n",
    "\n",
    "#acceptance rates in order: glitch RJ, glitch tau, wavelet RJ, wavelet tau, N/A, PT swap, fast, regular, noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c1bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee556e5",
   "metadata": {},
   "source": [
    "## Thinning chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8f014",
   "metadata": {},
   "source": [
    "# Diagnostic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2bd381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in n_chain:\n",
    "    burnin = int(len(log_likelihood[n])*0.35)#50_000\n",
    "    print('acc_frac: ', acc_frac[6][n])\n",
    "    print('max: ', max(log_likelihood[n, burnin:]))\n",
    "    print('min: ', min(log_likelihood[n, burnin:])) #burnin\n",
    "    plt.plot(log_likelihood[n,burnin:], label = 'QB')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5ddeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name_list = list(par_name.decode('utf-8') for par_name in param_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97622b99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4cd2c5",
   "metadata": {},
   "source": [
    "# Plot model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8abcc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting function for parameter posteriors/traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters(n_chain = 1, hist = False, params = None, corner_plot = False, burnin = 0, sky_params = [np.cos(np.pi/2), 3.7], curn_params = [13/3, -14.22], wavelet = False, density = False, num_wavelets = 1):\n",
    "    '''\n",
    "    :param n_chain: list of chain indexes to index samples array. [1] by default.\n",
    "    :param burnin: positive integer to set samples burnin. [0] by default.\n",
    "    :param hist: True returns histograms.\n",
    "    :param params: Can be one of ['Amp', 'sky_loc', 'All']. 'Amp' returns either histograms (or traces w/ hist = False)\n",
    "            for all amplitude parameters. 'sky_loc' returns corner plots of sky location parameters. \n",
    "    :param corner_plot: If True and hist = True, will return corner plots. [False] by default.\n",
    "    :param sky_params: If sky_loc = True, pass in param values in order (cos(theta_gw), gw_phi).\n",
    "    :param wavelet: Set to True to only get wavelet amplitude stuff.\n",
    "    :param density: If True, normalize histograms.\n",
    "    :param num_wavelets: Number of wavelets in corner plots. If wavelet = True and hist = True, must pass in a number of wavelets that is <= the number of wavelets in your chain. For example, \n",
    "                        if your chain has 5 wavelets, num_wavelets = 4 or less (starting at 0). \n",
    "    '''\n",
    "    \n",
    "    #burn samples for each chain. Get| rid of n_wavelet, n_glitch params.\n",
    "    samples_burned = samples[n_chain, burnin:, 2:]\n",
    "    print(np.shape(samples_burned))\n",
    "    #Number of samples for burned chain\n",
    "    num_samples = len(samples_burned[:, 0])\n",
    "    print('Number of samples: ', num_samples)\n",
    "    \n",
    "    #Overall param list \n",
    "    param_name_list = list(par_name.decode('utf-8') for par_name in param_names)\n",
    "    \n",
    "    #Catch all if params not set\n",
    "    if params == None:\n",
    "        raise ValueError('Must pick param type to print')\n",
    "        \n",
    "    #If plotting sky params, check if giving\n",
    "    if params == 'sky_loc' and (sky_params == None or len(sky_params) != 2):\n",
    "        raise AttributeError('Must input 2 params if wanting sky_loc params.')\n",
    "    \n",
    "    #Plotting histograms\n",
    "    if hist:\n",
    "        print('Plotting param histograms')\n",
    "        #If Amp and hist, plot either corner plots or histograms\n",
    "        if params == 'Amp':\n",
    "            print('Plotting amplitudes')\n",
    "            #Amp params and indexes in param list\n",
    "            amps = [[name, idx] for idx, name in enumerate(param_name_list) if 'log10_h' in name]\n",
    "            print(amps)\n",
    "            #Get only signal wavelet amplitudes\n",
    "            if wavelet:\n",
    "                if num_wavelets is None:\n",
    "                    raise ValueError('Must pass in number of wavelets')\n",
    "                else:\n",
    "                    wavelet_amps = [[par[0], par[1]] for par in amps if 'wavelet' in par[0]]\n",
    "                    amps = wavelet_amps\n",
    "                    \n",
    "                    #Select wavelets based on num_wavelets\n",
    "                    amps = amps[0:num_wavelets*2]\n",
    "                \n",
    "                \n",
    "            ranges = [[min(samples[n_chain, :, 2+amp[1]]), max(samples[n_chain, :, 2+amp[1]])] for amp in amps]\n",
    "            #Get param indexes\n",
    "            indexes = [entry[1] for entry in amps]\n",
    "            \n",
    "            #WIP 5/20/24 -> Corner plots taking very long to plot. Not sure why. Like.... too long to wait for.\n",
    "            if corner_plot:\n",
    "                print('Making amplitude corner plot')\n",
    "\n",
    "                #Make corner plot for amps\n",
    "                print('Testing with one wavelet')\n",
    "#                 amps_temp = amps[0:5]\n",
    "#                 print(amps)\n",
    "                data = np.zeros((len(amps), num_samples))\n",
    "                for idx, amp in enumerate(amps):\n",
    "#                     print(amp)\n",
    "                    #Loop through all samples for each parameter\n",
    "                    for kk in range(num_samples):\n",
    "                        data[idx, kk] = samples_burned[kk, amp[1]]\n",
    "                plt.close()\n",
    "                #Dynamically set labels and param ranges\n",
    "                figure = corner.corner(data.T, labels = [entry[0] for entry in amps], color = 'tab:blue', range = ranges) #range = ranges \n",
    "                plt.show()\n",
    "            \n",
    "            #Plot standard histograms for amp params \n",
    "            else:\n",
    "                print('Making amplitude histograms')\n",
    "\n",
    "                #Only plot noise transient/signal wavelet amplitudes\n",
    "                for amp in amps:\n",
    "                    print(amp)\n",
    "                    print([min(samples[n_chain, :, 2+amp[1]]), max(samples[n_chain, :, 2+amp[1]])])\n",
    "                    #Plot histogram with range based on overall samples array\n",
    "                    plt.hist(samples_burned[:, amp[1]], bins = 100, range = [min(samples[n_chain, :, 2+amp[1]]), max(samples[n_chain, :, 2+amp[1]])], histtype = 'step', density = density, color = 'red')\n",
    "                    plt.suptitle('Hist for: {}'.format(amp[0]))\n",
    "                    plt.show()\n",
    "                    \n",
    "        #Sky loc WIP 5/20/24\n",
    "        elif params == 'sky_loc':\n",
    "            print('Making sky location corner plot')\n",
    "            #Make corner plots for sky location parameters\n",
    "\n",
    "            #Sky param names (EDIT AS NEEDED)\n",
    "            sky_names = ['wavelet_0_cos_gwtheta', 'wavelet_0_gwphi'] #, 'wavelet_0_gw_psi'\n",
    "\n",
    "            #Get list of sky param names and indexes\n",
    "            sky_pars = [[par,idx] for idx, par in enumerate(param_name_list) if par in sky_names]\n",
    "\n",
    "            #Indexes in param list (if needed)\n",
    "            sky_indexes = [entry[1] for entry in sky_pars]\n",
    "\n",
    "            num_params = len(sky_pars)\n",
    "            \n",
    "            #Create data array based on number of sky location parameters\n",
    "            data = np.zeros((len(sky_pars), num_samples))\n",
    "            \n",
    "            for idx, sky_par in enumerate(sky_pars):\n",
    "                #Loop through all samples for each parameter\n",
    "                for kk in range(num_samples):\n",
    "                    data[idx, kk] = samples_burned[kk, sky_par[1]]\n",
    "\n",
    "            figure = corner.corner(data.T, labels = [r'$\\mathrm{cos}(\\theta_{gw})$', r'$\\phi_{gw}$'], color = 'tab:blue', range = [[-1,1],[0,2*np.pi]]) #r'$\\psi_{gw}$',\n",
    "            corner.overplot_lines(figure, [sky_params[0], sky_params[1]], color=\"C1\") #0\n",
    "            pulsar_cos_theta = []\n",
    "            pulsar_phi = []\n",
    "            for p in psrs[:]:\n",
    "                pulsar_cos_theta.append(np.cos(p.theta))\n",
    "                pulsar_phi.append(p.phi)\n",
    "            figure.axes[2].scatter(pulsar_cos_theta, pulsar_phi, marker='o', linewidth=1.4, color='xkcd:red') #, s=1/(t0_max-tspan)\n",
    "            plt.suptitle('Sky location parameters')\n",
    "            plt.show()\n",
    "        \n",
    "        #CURN WIP 6/12/24\n",
    "        elif params == 'CURN':\n",
    "            print('Making CURN corner plot')\n",
    "            #Make corner plots for CURN parameters\n",
    "            \n",
    "            curn_pars = [] \n",
    "            curn_indexes = []\n",
    "            \n",
    "            #Get list of CURN param names and indexes\n",
    "            for idx, par in enumerate(param_name_list):\n",
    "                if 'crn' in par:\n",
    "                    curn_pars.append(par)\n",
    "                    curn_indexes.append(param_name_list.index(par))\n",
    "\n",
    "            num_params = len(curn_pars)\n",
    "            \n",
    "            #Create data array based on number of sky location parameters\n",
    "            data = np.zeros((len(curn_pars), num_samples))\n",
    "            \n",
    "            for idx, curn_indx in enumerate(curn_indexes):\n",
    "                #Loop through all samples for each parameter\n",
    "                for kk in range(num_samples):\n",
    "                    data[idx, kk] = samples_burned[kk, curn_indx]\n",
    "\n",
    "            figure = corner.corner(data.T,bins = 50, labels = [r'$\\gamma$', r'$log_{10}A$'], color = 'tab:blue', range = [[0,7],[-20,-12]]) #r'$\\psi_{gw}$',\n",
    "            corner.overplot_lines(figure, [curn_params[0], curn_params[1]], color=\"C1\") #0\n",
    "            plt.suptitle('Varied CURN Parameters')\n",
    "#             plt.savefig(\"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Plots/Paper_Plots/Simple_20PSR_30Mpc_parabolic_flyby/CURNvarried_largeA_13_3_skyshift/CURN_corner.pdf\", dpi=600)\n",
    "            plt.show()\n",
    "\n",
    "        #Make histograms for all parameters\n",
    "        else:\n",
    "            print('Making histograms for all parameters')\n",
    "            for i, par in enumerate(param_name_list):\n",
    "                #Plot histogram with range based on overall samples array\n",
    "                plt.hist(samples_burned[:, i], bins = 100, range = [min(samples[n_chain, :, 2+i]), max(samples[n_chain, :, 2+i])], histtype = 'step', density = density, color = 'red')\n",
    "                plt.suptitle('Hist for: {}'.format(par))\n",
    "                plt.show()\n",
    "                \n",
    "    #Plotting parameter traces\n",
    "    else:\n",
    "        print('Plotting param traces')\n",
    "        if params == 'Amp':\n",
    "            print('Plotting amplitude traces')\n",
    "            #Amp params and indexes in param list\n",
    "            amps = [[name, idx] for idx, name in enumerate(param_name_list) if 'log10_h' in name]\n",
    "            \n",
    "            #Only plot noise transient/signal wavelet amplitude traces\n",
    "            for amp in amps:    \n",
    "                plt.plot(samples_burned[:, amp[1]], color = 'red')\n",
    "                plt.ylim((min(samples[n_chain, :, 2+amp[1]]), max(samples[n_chain, :, 2+amp[1]])))\n",
    "                plt.suptitle('Param trace for: {}'.format(amp[0]))\n",
    "                plt.show()\n",
    "                \n",
    "        #If hist = false and params == 'sky_loc', plot traces for sky location params\n",
    "        if params == 'sky_loc':\n",
    "            print('Plotting sky location traces')\n",
    "            \n",
    "            #Sky param names\n",
    "            sky_names = ['wavelet_0_cos_gwtheta', 'wavelet_0_gwphi']\n",
    "            #Amp params and indexes in param list\n",
    "            sky_pars = [[name, idx] for idx, name in enumerate(param_name_list) if name in sky_names]\n",
    "            \n",
    "            #Only plot noise transient/signal wavelet amplitude traces\n",
    "            for sky_par in sky_pars:    \n",
    "                plt.plot(samples_burned[:, sky_par[1]], color = 'red')\n",
    "                plt.ylim((min(samples[n_chain, :, 2+sky_par[1]]), max(samples[n_chain, :, 2+sky_par[1]])))\n",
    "                if 'cos' in sky_par[0]:\n",
    "                    plt.axhline(y = sky_params[0])\n",
    "                    plt.ylim((-np.pi/2, np.pi/2))\n",
    "                if 'phi' in sky_par[0]:\n",
    "                    plt.axhline(y = sky_params[1])\n",
    "                    plt.ylim((0, 2*np.pi))\n",
    "                plt.suptitle('Param trace for: {}'.format(sky_par[0]))\n",
    "                plt.show()\n",
    "        \n",
    "        #Plot all parameter traces\n",
    "        else:\n",
    "            print('Plotting traces for all parameters')\n",
    "            for i, par in enumerate(param_name_list):\n",
    "                plt.plot(samples_burned[:, i], color = 'red')\n",
    "                plt.ylim((min(samples[n, :, 2+i]), max(samples[n, :, 2+i])))\n",
    "                plt.suptitle('Param trace for: {}'.format(par))\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b54e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_chain = 0\n",
    "burnin = int(len(log_likelihood[n_chain])*0.25)\n",
    "\n",
    "#Implement savepath\n",
    "parameters(n_chain = n_chain, params = 'CURN', hist = True, corner_plot = True, wavelet = True, burnin = burnin, density = True, num_wavelets = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d15bc",
   "metadata": {},
   "source": [
    "# Curn comparisons for M2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887391f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from la_forge.core import Core\n",
    "from la_forge.diagnostics import plot_chains\n",
    "from la_forge.rednoise import plot_rednoise_spectrum\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2edc8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_direc = '/home/user/path_to/m2a_chain'\n",
    "m2aCore = Core(label=\"chain_1\",chaindir=chain_direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852acba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chain = 0\n",
    "burnin = int(len(log_likelihood[n_chain])*0.25)\n",
    "#burn samples for each chain. Get| rid of n_wavelet, n_glitch params.\n",
    "samples_burned = samples[n_chain, burnin:, 2:]\n",
    "print(np.shape(samples_burned))\n",
    "#Number of samples for burned chain\n",
    "num_samples = len(samples_burned[:, 0])\n",
    "print('Number of samples: ', num_samples)\n",
    "\n",
    "#Overall param list \n",
    "param_name_list = list(par_name.decode('utf-8') for par_name in param_names)\n",
    "curn_params = [13/3, -14.22]\n",
    "\n",
    "print('Making CURN corner plot')\n",
    "\n",
    "curn_names = ['com_rn_gamma', 'com_rn_log10_A'] \n",
    "\n",
    "#Get list of sky param names and indexes\n",
    "curn_pars = [[par,idx] for idx, par in enumerate(param_name_list) if par in curn_names]\n",
    "\n",
    "#Indexes in param list (if needed)\n",
    "curn_indexes = [entry[1] for entry in curn_pars]\n",
    "\n",
    "num_params = len(curn_pars)\n",
    "\n",
    "#Create data array for CURN parameters\n",
    "data = np.zeros((len(curn_pars), num_samples))\n",
    "\n",
    "for idx, curn_par in enumerate(curn_pars):\n",
    "    #Loop through all samples for each parameter\n",
    "    for kk in range(num_samples):\n",
    "        data[idx, kk] = samples_burned[kk, curn_par[1]]\n",
    "        \n",
    "data_m2a = np.zeros((len(curn_pars), len(m2aCore.get_param('gw_gamma'))))  \n",
    "gw_gamma_m2a = m2aCore.get_param('gw_gamma')\n",
    "gw_log10_A_m2a = m2aCore.get_param('gw_log10_A')\n",
    "\n",
    "for kk in range(len(gw_gamma_m2a)):\n",
    "    data_m2a[0, kk] = gw_gamma_m2a[kk]\n",
    "    data_m2a[1, kk] = gw_log10_A_m2a[kk]\n",
    "        \n",
    "\n",
    "figure = corner.corner(data.T,bins = 50, labels = [r'$\\mathrm{\\gamma}$', r'$\\mathrm{log_{10}A}$'], color = 'tab:blue', range = [[2,7],[-16,-13]], weights = np.ones(len(data[0]))/len(data[0]),fill_contours=True) #r'$\\psi_{gw}$',\n",
    "corner.corner(data_m2a.T,bins = 50, labels = [r'$\\mathrm{\\gamma}$', r'$\\mathrm{log_{10}A}$'], color = 'tab:red', range = [[2,7],[-16,-13]],fig = figure, weights = np.ones(len(data_m2a[0]))/len(data_m2a[0]), fill_contours=True)\n",
    "corner.overplot_lines(figure, [curn_params[0], curn_params[1]], color=\"black\",linestyle = '-') #0\n",
    "corner.overplot_lines(figure, [np.median(data[0]), np.median(data[1])], color=\"blue\",linestyle = '--') #0\n",
    "corner.overplot_lines(figure, [np.median(data_m2a[0]), np.median(data_m2a[1])], color=\"red\",linestyle = '--') #0\n",
    "\n",
    "colors = ['red', 'blue']\n",
    "sample_labels = ['Enterprise', 'QuickBurst']\n",
    "\n",
    "plt.legend(\n",
    "    handles = [\n",
    "        mlines.Line2D([], [], color = colors[i], label = sample_labels[i]) for i in range(len(sample_labels))             \n",
    "    ],\n",
    "    fontsize = 14, frameon = False,\n",
    "    bbox_to_anchor = (1,2), loc = \"upper right\"\n",
    ")\n",
    "plt.suptitle('Varied CURN Parameters')\n",
    "plt.savefig(\"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Plots/Paper_Plots/Simple_20PSR_30Mpc_parabolic_flyby/CURNvarried_largeA_13_3_skyshift/CURN_corner_combined.pdf\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1aec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('m2a medians gamma={0}, and Log10_A={1}'.format(np.median(data_m2a[0]),np.median(data_m2a[1])))\n",
    "print('Quick Burst medians gamma={0}, and Log10_A={1}'.format(np.median(data[0]),np.median(data[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106abbcc",
   "metadata": {},
   "source": [
    "# Make corner plots for sky location parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a01b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = []\n",
    "indexes = []\n",
    "\n",
    "param_name_list = list(par_name.decode('utf-8') for par_name in param_names)\n",
    "\n",
    "####\n",
    "#for sky location and polarization\n",
    "####\n",
    "sky_names = ['wavelet_0_cos_gwtheta', 'wavelet_0_gwphi'] #, 'wavelet_0_gw_psi'\n",
    "sky_pars = []\n",
    "sky_indexes = []\n",
    "for ii in range(len(param_name_list)):\n",
    "    if param_name_list[ii] in sky_names:\n",
    "        sky_pars.append(param_name_list[ii])\n",
    "        sky_indexes.append(ii)\n",
    "\n",
    "param_list.append(sky_pars)\n",
    "indexes.append(sky_indexes)\n",
    "    \n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bce0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b190e7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(len(samples_array[0, 0, :]))\n",
    "#Loop through number of parameters per pulsar (noise params)\n",
    "burnin = int(len(log_likelihood[n_chain])*0.30)\n",
    "num_samples = len(samples_array[0,burnin:,0])\n",
    "num_params = len(param_list)\n",
    "print(num_params-2, num_samples)\n",
    "chain_num = 0\n",
    "    \n",
    "#Loop through sky params\n",
    "for ii in range(0, num_params):\n",
    "    print(param_names[ii])\n",
    "    data = np.zeros((len(param_list[ii]), num_samples))\n",
    "    #print(ii)\n",
    "    #Loop through all samples for each parameter\n",
    "    for jj in range(len(indexes[ii])):\n",
    "        temp_index = indexes[ii][jj]\n",
    "        for kk in range(num_samples):\n",
    "            data[jj, kk] = samples_array[chain_num, burnin+kk, temp_index+2]\n",
    "    \n",
    "    #Making corner plot for each pulsar\n",
    "    plt.close()\n",
    "    \n",
    "    #Make sure values are correct in corner.overplot_lines()\n",
    "    figure = corner.corner(data.T, labels = [r'$\\mathrm{cos}(\\theta_{gw})$', r'$\\phi_{gw}$'], color = 'tab:blue', range = [[-1,1],[0,2*np.pi]]) #r'$\\psi_{gw}$',\n",
    "    corner.overplot_lines(figure, [np.cos(np.pi/2), 3.7], color=\"C1\") #0\n",
    "    pulsar_cos_theta = []\n",
    "    pulsar_phi = []\n",
    "    for p in psrs[:]:\n",
    "        pulsar_cos_theta.append(np.cos(p.theta))\n",
    "        pulsar_phi.append(p.phi)\n",
    "    figure.axes[2].scatter(pulsar_cos_theta, pulsar_phi, marker='o', linewidth=1.4, color='xkcd:red') #, s=1/(t0_max-tspan)\n",
    "    plt.suptitle('Simple 20 pulsar dataset')\n",
    "#     plt.savefig(\"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Plots/Paper_Plots/60Mpc_RN/10yrs_psrs/sky_location_corner_plus_pulsars.pdf\", dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4303bc",
   "metadata": {},
   "source": [
    "# Creating quantile plots for convergence testing\n",
    "### Not terribly informative for parameters that only sample subset of parameter range (but uniformly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0489cd2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def uniform_quantiles(chain, low, high, num_reals=1_000):\n",
    "    integrated_time = emcee.autocorr.integrated_time(chain, c=10, quiet=False)\n",
    "    print(integrated_time)\n",
    "    data = chain[::int(np.ceil(integrated_time))]\n",
    "    # bootstrap for error bounds\n",
    "    d = np.random.uniform(low, high, size=(len(data), num_reals))\n",
    "    x = np.linspace(0, 1, num=100)\n",
    "    avg = np.mean(np.quantile(d, x, axis=0), axis=1)\n",
    "    std = np.std(np.quantile(d, x, axis=0), axis=1)\n",
    "    return np.quantile(data, x), avg, std\n",
    "\n",
    "burnin = int(0.25*len(samples[0,:,0:]))\n",
    "#print(burnin)\n",
    "thin = 10\n",
    "#print(samples_array[0, burnin:, :])\n",
    "print(param_names)\n",
    "\n",
    "for i, par in enumerate(param_names):\n",
    "    string = str(par)\n",
    "    if 'log10' in string:\n",
    "        continue;\n",
    "    quantiles, avg, std = uniform_quantiles(samples[0, burnin:,i+2],\n",
    "                                                np.min(samples[0, burnin:,i+2]),\n",
    "                                                np.max(samples[0, burnin:,i+2]), num_reals=100)\n",
    "    plt.figure(2*i, figsize=(10, 10))\n",
    "    for j in range(-3, 4):\n",
    "        plt.plot(avg, avg + j * std, color='gray', alpha=0.5, marker='.')\n",
    "    plt.plot(avg, quantiles)\n",
    "    plt.title(par)\n",
    "    \n",
    "    plt.figure(2*i+1, figsize=(10, 3))\n",
    "    for j in range(-3, 4):\n",
    "        plt.plot(avg, avg*0.0 + j * std, color='gray', alpha=0.5, marker='.')\n",
    "    plt.plot(avg, quantiles-avg)\n",
    "    plt.title(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8450e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emcee.autocorr.integrated_time(np.random.normal(size=100), c=10, quiet=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d9072",
   "metadata": {},
   "source": [
    "# NUMBER OF WAVELETS HISTOGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f79f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#\n",
    "# NUMBER OF WAVELETS HISTOGRAM\n",
    "#\n",
    "#################################################################\n",
    "\n",
    "#do not replace 0s with nans in this case\n",
    "n_chain = 0\n",
    "burnin = int(len(log_likelihood[n_chain])*0.25)\n",
    "samples_burned = samples[n_chain,burnin:,:]\n",
    "\n",
    "max_corr_l=0.001\n",
    "\n",
    "print(int(np.nanmax(samples_burned[:,0])))\n",
    "#bins = np.arange(-1,int(np.nanmax(samples_burned[:,0]))+1) + 0.5\n",
    "########################################\n",
    "min_n = 0\n",
    "max_n = 5\n",
    "########################################\n",
    "bins = np.arange(min_n-1,max_n+1) + 0.5\n",
    "print(bins)\n",
    "N = np.shape(samples_burned[:,0])[0]\n",
    "print(N)\n",
    "hist, bin_edges = np.histogram(samples_burned[:,0], bins)\n",
    "print(hist/N*100)\n",
    "poisson_error = np.sqrt(hist/max_corr_l)/(N/max_corr_l)*100\n",
    "print(poisson_error)\n",
    "plt.bar(bin_edges[:-1]+0.5, hist/N*100, yerr=poisson_error, fill=False, edgecolor='b', linewidth=2, ecolor='b',\n",
    "        capsize=None, error_kw={'elinewidth':2}, label='posterior')\n",
    "\n",
    "bin_edges_signal = bin_edges\n",
    "hist_signal = hist\n",
    "\n",
    "########################################\n",
    "n_source_prior = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "########################################\n",
    "prior_hist = n_source_prior/np.sum(n_source_prior)*100\n",
    "plt.bar(bin_edges[:-1]+0.5, prior_hist, fill=False, edgecolor='r', linewidth=2, ls='--',\n",
    "        label='prior')\n",
    "\n",
    "plt.legend(loc=3)\n",
    "#plt.yscale('log', nonposy='clip')\n",
    "plt.xlabel(\"Number of wavelets\")\n",
    "plt.ylabel(\"% of samples\")\n",
    "\n",
    "plt.xticks(np.arange(min_n, max_n+1, step=1.0))\n",
    "\n",
    "bayes_factor = hist[1]/hist[0]*n_source_prior[0]/n_source_prior[1] #compensating for our non-uniform prior\n",
    "\n",
    "print(poisson_error/(hist/N*100))\n",
    "\n",
    "bf_error = np.sum(poisson_error/(hist/N*100))*bayes_factor\n",
    "\n",
    "print(\"best prior would have been: n_source_prior= \",1/hist*prior_hist*1000)\n",
    "\n",
    "#plt.text(0.65,60,r'$B_{{\\rm GWB}}^{{\\rm RJ}}={0:.4f}\\pm {1:.4f}$'.format(bayes_factor, bf_error), fontdict={'size':10})\n",
    "#plt.title(r'$B_{{\\rm CW}}^{{\\rm RJ}}={0:.4f}\\pm {1:.4f}$'.format(bayes_factor, bf_error))\n",
    "\n",
    "#plt.axhline(y=100.0/np.max(samples_burned[:,0]), color='r')\n",
    "#plt.ylim((20,30))\n",
    "#plt.xlim((0.5,3.0))\n",
    "plt.grid(which='both')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Plots/Paper_Plots/60Mpc_RN/10yrs_psrs/Signal_wavelet_recovery.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daef74f",
   "metadata": {},
   "source": [
    "# NUMBER OF GLITCHES HISTOGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8619a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#\n",
    "# NUMBER OF GLITCHES HISTOGRAM\n",
    "#\n",
    "#################################################################\n",
    "\n",
    "\n",
    "max_corr_l=0.001\n",
    "\n",
    "print(int(np.nanmax(samples_burned[:,1])))\n",
    "#bins = np.arange(-1,int(np.nanmax(samples_burned[:,0]))+1) + 0.5\n",
    "########################################\n",
    "min_n = 0\n",
    "max_n = 5\n",
    "########################################\n",
    "bins = np.arange(min_n-1,max_n+1) + 0.5\n",
    "print(bins)\n",
    "N = np.shape(samples_burned[:,1])[0]\n",
    "print(N)\n",
    "hist, bin_edges = np.histogram(samples_burned[:,1], bins)\n",
    "print(hist/N*100)\n",
    "poisson_error = np.sqrt(hist/max_corr_l)/(N/max_corr_l)*100\n",
    "print(poisson_error)\n",
    "plt.bar(bin_edges[:-1]+0.5, hist/N*100, yerr=poisson_error, fill=False, edgecolor='b', linewidth=2, ecolor='b',\n",
    "        capsize=None, error_kw={'elinewidth':2}, label='posterior')\n",
    "\n",
    "bin_edges_glitch = bin_edges\n",
    "hist_glitch = hist\n",
    "\n",
    "########################################\n",
    "n_source_prior = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "#n_source_prior = np.ones(25+1)\n",
    "########################################\n",
    "prior_hist = n_source_prior/np.sum(n_source_prior)*100\n",
    "plt.bar(bin_edges[:-1]+0.5, prior_hist, fill=False, edgecolor='r', linewidth=2, ls='--',\n",
    "        label='prior')\n",
    "\n",
    "plt.legend(loc=3)\n",
    "#plt.yscale('log', nonposy='clip')\n",
    "plt.xlabel(\"Number of glitches\")\n",
    "plt.ylabel(\"% of Samples\")\n",
    "\n",
    "plt.xticks(np.arange(min_n, max_n+1, step=1.0))\n",
    "\n",
    "bayes_factor = hist[1]/hist[0]*n_source_prior[0]/n_source_prior[1] #compensating for our non-uniform prior\n",
    "\n",
    "print(poisson_error/(hist/N*100))\n",
    "\n",
    "bf_error = np.sum(poisson_error/(hist/N*100))*bayes_factor\n",
    "\n",
    "print(\"best prior would have been: n_source_prior= \",1/hist*prior_hist*1000)\n",
    "\n",
    "#plt.text(0.65,60,r'$B_{{\\rm GWB}}^{{\\rm RJ}}={0:.4f}\\pm {1:.4f}$'.format(bayes_factor, bf_error), fontdict={'size':10})\n",
    "#plt.title(r'$B_{{\\rm CW}}^{{\\rm RJ}}={0:.4f}\\pm {1:.4f}$'.format(bayes_factor, bf_error))\n",
    "\n",
    "#plt.axhline(y=100.0/np.max(samples_burned[:,0]), color='r')\n",
    "#plt.ylim((20,30))\n",
    "#plt.xlim((0.5,3.0))\n",
    "plt.grid(which='both')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Plots/Paper_Plots/60Mpc_RN/10yrs_psrs/Noise_wavelet_recovery.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62939045",
   "metadata": {},
   "source": [
    "# Combined Wavelet + Glitch histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483251cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not replace 0s with nans in this case\n",
    "n_chain = 0\n",
    "burnin = int(len(log_likelihood[n_chain])*0.50)\n",
    "samples_burned = samples[n_chain,burnin:,:]\n",
    "max_corr_l=0.001\n",
    "\n",
    "########################################\n",
    "#GLITCH HISTOGRAM\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "glitch_min_n = 0\n",
    "glitch_max_n = 5\n",
    "########################################\n",
    "glitch_bins = np.arange(glitch_min_n-1,glitch_max_n+1) + 0.5\n",
    "print(glitch_bins)\n",
    "N = np.shape(samples_burned[:,1])[0]\n",
    "print(N)\n",
    "\n",
    "glitch_hist, glitch_bin_edges = np.histogram(samples_burned[:,1], glitch_bins)\n",
    "glitch_poisson_error = np.sqrt(glitch_hist/max_corr_l)/(N/max_corr_l)*100\n",
    "print(glitch_poisson_error)\n",
    "\n",
    "print('Probability of wavelet per bin: ', [glitch_hist[i]/N for i in range(len(glitch_hist))])\n",
    "plt.bar(glitch_bin_edges[:-1]+0.5, glitch_hist/N*100, yerr=glitch_poisson_error, fill=False, alpha = 0.5, edgecolor='red', linewidth=2,\n",
    "        capsize=None, hatch = \"x\", error_kw={'elinewidth':2}, label='Noise Transient Posterior')\n",
    "\n",
    "\n",
    "########################################\n",
    "wavelet_min_n = 0\n",
    "wavelet_max_n = 5\n",
    "########################################\n",
    "wavelet_bins = np.arange(wavelet_min_n-1,wavelet_max_n+1) + 0.5\n",
    "print(wavelet_bins)\n",
    "\n",
    "wavelet_hist, wavelet_bin_edges = np.histogram(samples_burned[:,0], wavelet_bins)\n",
    "wavelet_poisson_error = np.sqrt(wavelet_hist/max_corr_l)/(N/max_corr_l)*100\n",
    "print(wavelet_poisson_error)\n",
    "\n",
    "print('Probability of wavelet per bin: ', [wavelet_hist[i]/N for i in range(len(wavelet_hist))])\n",
    "plt.bar(wavelet_bin_edges[:-1]+0.5, wavelet_hist/N*100, yerr=wavelet_poisson_error, fill=False, alpha = 0.5, edgecolor='blue', linewidth=2, \n",
    "        capsize=None, hatch = \".\", error_kw={'elinewidth':2}, label='Signal Wavelet Posterior')\n",
    "\n",
    "########################################\n",
    "n_source_prior = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "#n_source_prior = np.ones(25+1)\n",
    "########################################\n",
    "prior_hist = n_source_prior/np.sum(n_source_prior)*100\n",
    "plt.bar(wavelet_bin_edges[:-1]+0.5, prior_hist, fill=False, edgecolor='green', linewidth=2, ls='--',\n",
    "        label='Bayesian prior')\n",
    "\n",
    "plt.ylim((0, 105))\n",
    "plt.xlabel(\"Number of wavelets\")\n",
    "plt.ylabel(\"% of Samples\")\n",
    "plt.grid(which='both')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "# plt.savefig(\"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Plots/Paper_Plots/Simple_20PSR_30Mpc_parabolic_flyby/CURNvarried_largeA_13_3_skyshift/Wavelet_glitch_posterior.pdf\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cb1a4d",
   "metadata": {},
   "source": [
    "# BAYESOGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc01ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Loading in pickle and noise files for 2 wavelet\n",
    "noise_file_sim = \"/home/user/path_to/.../noise_dict.json\"\n",
    "with open(noise_file_sim, 'r') as h:\n",
    "    noise_params = json.load(h)\n",
    "noise_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c314a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting dataset max time and reference time\n",
    "maximum = 0\n",
    "minimum = np.inf\n",
    "for psr in psrs:\n",
    "    if psr.toas.max() > maximum:\n",
    "        maximum = psr.toas.max()\n",
    "    if psr.toas.min() < minimum:\n",
    "        minimum = psr.toas.min()\n",
    "\n",
    "\n",
    "#Sets reference time\n",
    "tref = minimum\n",
    "\n",
    "t0_max = (maximum - minimum)/365/24/3600\n",
    "print(t0_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e7621",
   "metadata": {},
   "source": [
    "## Setting up components for reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7febc400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from la_forge.gp import Signal_Reconstruction as gp\n",
    "from la_forge.utils import epoch_ave_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4267f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set to True if no burst injection in dataset\n",
    "#Will set burst injection curve to 0.\n",
    "no_burst = False\n",
    "\n",
    "############################################################\n",
    "#\n",
    "#BAYESOGRAMS 2?\n",
    "#\n",
    "############################################################\n",
    "def WNBSimulator(t, A, t0, f0, delt, delf, wnb_seed):\n",
    "    \n",
    "    #generate white noise in time domain first\n",
    "    np.random.seed(wnb_seed)\n",
    "    h_plus = np.random.normal(scale=A, size=t.size)\n",
    "    h_cross = np.random.normal(scale=A, size=t.size)\n",
    "\n",
    "    #widnow it in the time domain\n",
    "    h_plus *= np.exp(-(t-t0)**2/delt**2)\n",
    "    h_cross *= np.exp(-(t-t0)**2/delt**2)\n",
    "\n",
    "    #fft them\n",
    "    h_plus = np.fft.rfft(h_plus)\n",
    "    h_cross = np.fft.rfft(h_cross)\n",
    "    f = np.fft.rfftfreq(t.size, d=t[1]-t[0])\n",
    "    #print(f)\n",
    "\n",
    "    #window it in the frequency domain\n",
    "    h_plus *= np.exp(-(f-f0)**2/delf**2)\n",
    "    h_cross *= np.exp(-(f-f0)**2/delf**2)\n",
    "\n",
    "    #ifft them back to time domain\n",
    "    h_plus = np.fft.irfft(h_plus)\n",
    "    h_cross = np.fft.irfft(h_cross)\n",
    "    \n",
    "    return h_plus, h_cross\n",
    "\n",
    "def parabolic_signal(t, m1, m2, b, t_pericenter, dist, tref):\n",
    "    #total mass\n",
    "    M = m1+m2\n",
    "    #reduced mass\n",
    "    mu = m1*m2/M\n",
    "    #print(t + tref - t_pericenter*24*3600)\n",
    "    #time vector shifted so that ttt=0 at pericenter passage\n",
    "    ttt = t + tref - t_pericenter*24*3600 #seconds\n",
    "    speed_of_light = 299792458.0 #m/s\n",
    "    T_sun = 1.327124400e20 / speed_of_light**3 #G*M_sun/c^3 = R_sun/c-->Sun time\n",
    "    ttt *= 1/T_sun\n",
    "\n",
    "    #pc to meter\n",
    "    pc_meter = 3.08567758149137e16\n",
    "\n",
    "    #parameters from Finn&Lommen(2010) eq. (4-2d) and (4-2e)\n",
    "    w0 = np.sqrt(8+9*M/b*(ttt/b)**2)\n",
    "    w1 = (3*ttt/b*np.sqrt(M/b)+w0)**(1/3)\n",
    "\n",
    "    #calculate quadrupole moment time derivatives -- Finn&Lommen(2010) eq. (4-3a-c)\n",
    "    Q_xx_dot = mu*b/(np.sqrt(2)*w0*w1**4) * np.sqrt(M/b) * (w1**4-4) * (w1**4-6*w1**2+4)  #solar mass**2\n",
    "    Q_yy_dot = 4*mu*b/(w0*w1**2) * np.sqrt(M/b) * (w1**4-4)                               #solar mass**2\n",
    "    Q_xy_dot = mu*b/(np.sqrt(2)*w0*w1**3) * np.sqrt(M/b) * (-3*w1**6+8*w1**4+16*w1**2-24) #solar mass**2\n",
    "    \n",
    "    H_plus = 2/(dist*1e6*pc_meter/speed_of_light/T_sun)*(Q_xx_dot-Q_yy_dot) #solar mass\n",
    "    H_cross = 2/(dist*1e6*pc_meter/speed_of_light/T_sun)*2*Q_xy_dot #solar mass\n",
    "\n",
    "    H_plus *= T_sun #seconds\n",
    "    H_cross *= T_sun #seconds\n",
    "    \n",
    "    return H_plus, H_cross\n",
    "\n",
    "# thin=100\n",
    "thin=1000\n",
    "#thin = 3000\n",
    "rnd_i = 20#68#42#56\n",
    "\n",
    "print('Thinned samples_burned shape: ', samples_burned[::thin,:].shape)\n",
    "\n",
    "\n",
    "'''\n",
    "PTA generation below. Settings need to change for each run.\n",
    "'''\n",
    "\n",
    "n_chain = 0\n",
    "\n",
    "#If chain is thinned, use regular samples\n",
    "burnin = int(len(samples[n_chain,:,0])*0.35)#50_000\n",
    "samples_burned = samples[n_chain,burnin:,:]\n",
    "print('samples_burned shape: ', np.shape(samples_burned))\n",
    "\n",
    "max_n_wavelets = 5\n",
    "max_n_glitches = 3\n",
    "PTA, QB_FP, QB_FPI, glitch_indx, wavelet_indx, per_puls_indx, rn_indx, num_per_puls_wn_param_list = QB_mcmc.get_pta(psrs, \n",
    "                                                                                                            vary_white_noise = False,\n",
    "                                                                                                            max_n_wavelet=max_n_wavelets, \n",
    "                                                                                                            max_n_glitch=max_n_glitches,   \n",
    "                                                                                                            include_equad = True, \n",
    "                                                                                                            include_ecorr = False, \n",
    "                                                                                                            wn_backend_selection=False, \n",
    "                                                                                                            noisedict=noise_params, \n",
    "                                                                                                            include_efac=True,\n",
    "                                                                                                            include_rn=False, \n",
    "                                                                                                            vary_rn=False, \n",
    "                                                                                                            include_per_psr_rn=False, \n",
    "                                                                                                            vary_per_psr_rn=False, t0_max = t0_max, tref = tref) \n",
    "\n",
    "print(wavelet_indx)\n",
    "print(glitch_indx)\n",
    "\n",
    "###################\n",
    "#GW delays\n",
    "###################\n",
    "\n",
    "#get max number of observations\n",
    "print([psrs[i].toas.shape[0] for i in range(len(psrs))])\n",
    "max_obs = np.max([psrs[i].toas.shape[0] for i in range(len(psrs))])\n",
    "print(max_obs)\n",
    "\n",
    "#get all the delays from samples\n",
    "all_delays = np.zeros( (int(samples_burned.shape[0]/thin), len(psrs), max_obs) )\n",
    "print('Shape of all_delays: ', np.shape(all_delays))\n",
    "for ii in range(int(samples_burned.shape[0]/thin)):\n",
    "    \n",
    "    n_wavelet = int(samples_burned[ii*thin,0])\n",
    "\n",
    "    xxx = {}\n",
    "    for jj in range(n_wavelet):\n",
    "        xxx['wavelet_'+str(jj)+\"_cos_gwtheta\"] = samples_burned[ii*thin,2+wavelet_indx[jj,0]]\n",
    "        xxx['wavelet_'+str(jj)+\"_gw_psi\"] = samples_burned[ii*thin,2+wavelet_indx[jj,1]]\n",
    "        xxx['wavelet_'+str(jj)+\"_gwphi\"] = samples_burned[ii*thin,2+wavelet_indx[jj,2]]\n",
    "        xxx['wavelet_'+str(jj)+\"_log10_f0\"] = samples_burned[ii*thin,2+wavelet_indx[jj,3]]\n",
    "        xxx['wavelet_'+str(jj)+\"_log10_h\"] = samples_burned[ii*thin,2+wavelet_indx[jj,4]]\n",
    "        xxx['wavelet_'+str(jj)+\"_log10_h_cross\"] = samples_burned[ii*thin,2+wavelet_indx[jj,5]]\n",
    "        xxx['wavelet_'+str(jj)+\"_phase0\"] = samples_burned[ii*thin,2+wavelet_indx[jj,6]]\n",
    "        xxx['wavelet_'+str(jj)+\"_phase0_cross\"] = samples_burned[ii*thin,2+wavelet_indx[jj,7]]\n",
    "        xxx['wavelet_'+str(jj)+\"_t0\"] = samples_burned[ii*thin,2+wavelet_indx[jj,8]]\n",
    "        xxx['wavelet_'+str(jj)+\"_tau\"] = samples_burned[ii*thin,2+wavelet_indx[jj,9]]\n",
    "\n",
    "    delay_all_psr = PTA.get_delay(xxx)\n",
    "    for kk in range(len(psrs)):\n",
    "        all_delays[ii,kk,:psrs[kk].toas.shape[0]] = delay_all_psr[kk]\n",
    "        \n",
    "#     if ii==rnd_i:\n",
    "#         print(\"Random draw samples:\")\n",
    "#         print(samples_burned[ii*thin,:])\n",
    "#         delay_rnd_draw = np.copy(delay_all_psr)\n",
    "#         wavelets_rnd_draw = np.zeros( (int(n_wavelet), len(psrs), max_obs), dtype = \"object\")\n",
    "#         print('wavelets_rnd_draw: ', np.shape(wavelets_rnd_draw))\n",
    "#         #print(n_wavelet)\n",
    "#         #print(xxx)\n",
    "#         for jj in range(n_wavelet):\n",
    "#             print({key:xxx[key] for key in xxx.keys() if key[0]==str(jj)})\n",
    "#             wavelets_rnd_draw[jj,:,:] = PTA.get_delay({key:xxx[key] for key in xxx.keys() if key[0]==str(jj)})\n",
    "            #print(wavelets_rnd_draw[jj,0,:])\n",
    "\n",
    "#print(delay_rnd_draw.shape)\n",
    "#print(wavelets_rnd_draw.shape)\n",
    "#print(wavelets_rnd_draw)\n",
    "\n",
    "print(all_delays.shape)\n",
    "    \n",
    "#calculate median and 90%CI delay\n",
    "median_delays = np.zeros( (len(psrs), max_obs) )\n",
    "lower90_delays = np.zeros( (len(psrs), max_obs) )\n",
    "upper90_delays = np.zeros( (len(psrs), max_obs) )\n",
    "for kk in range(len(psrs)):\n",
    "    for ll in range(psrs[kk].toas.shape[0]):\n",
    "        median_delays[kk,ll] = np.median(all_delays[:,kk,ll])\n",
    "        upper90_delays[kk,ll] = np.percentile(all_delays[:,kk,ll], 95)\n",
    "        lower90_delays[kk,ll] = np.percentile(all_delays[:,kk,ll], 5)\n",
    "\n",
    "# Use models.wavelet_delay with median_delay wavelet parameter values to plot over residuals (and superimpose all wavelets)\n",
    "\n",
    "###################\n",
    "#Glitch delays\n",
    "###################\n",
    "\n",
    "#get all the delays from samples\n",
    "#all_glitch_delays[sample, psr, MJD] -> [sample, psr, 0] corresponds to the starting observing MJD for psr. i.e. MJD ~2008 for B1855.\n",
    "all_glitch_delays = np.zeros( (int(samples_burned.shape[0]/thin), len(psrs), max_obs) )\n",
    "for ii in range(int(samples_burned.shape[0]/thin)):\n",
    "    #print(ii)\n",
    "    n_glitch = int(samples_burned[ii*thin,1])\n",
    "    xxx = {}\n",
    "    for jj in range(n_glitch):\n",
    "        xxx[\"Glitch_\"+str(jj)+\"_log10_f0\"] = samples_burned[ii*thin,2+glitch_indx[jj,0]]\n",
    "        xxx[\"Glitch_\"+str(jj)+\"_log10_h\"] = samples_burned[ii*thin,2+glitch_indx[jj,1]]\n",
    "        xxx[\"Glitch_\"+str(jj)+\"_phase0\"] = samples_burned[ii*thin,2+glitch_indx[jj,2]]\n",
    "        xxx[\"Glitch_\"+str(jj)+\"_psr_idx\"] = samples_burned[ii*thin,2+glitch_indx[jj,3]]\n",
    "        xxx[\"Glitch_\"+str(jj)+\"_t0\"] = samples_burned[ii*thin,2+glitch_indx[jj,4]]\n",
    "        xxx[\"Glitch_\"+str(jj)+\"_tau\"] = samples_burned[ii*thin,2+glitch_indx[jj,5]]\n",
    "\n",
    "    \n",
    "    #print(samples_burned[burnin+ii,:])\n",
    "    #print(xxx)\n",
    "    delay_all_psr_glitch = PTA.get_delay(xxx)\n",
    "    for kk in range(len(psrs)):\n",
    "        all_glitch_delays[ii,kk,:psrs[kk].toas.shape[0]] = delay_all_psr_glitch[kk]\n",
    "        \n",
    "    #if ii==rnd_i:\n",
    "    #    delay_rnd_draw = np.copy(delay_all_psr)\n",
    "    #    wavelets_rnd_draw = np.zeros( (int(n_wavelet), len(psrs), psrs[0].toas.shape[0]) )\n",
    "    #    print(n_wavelet)\n",
    "    #    print(xxx)\n",
    "    #    for jj in range(n_wavelet):\n",
    "    #        print({key:xxx[key] for key in xxx.keys() if key[0]==str(jj)})\n",
    "    #        wavelets_rnd_draw[jj,:,:] = pta.get_delay({key:xxx[key] for key in xxx.keys() if key[0]==str(jj)})\n",
    "    #        print(wavelets_rnd_draw[jj,0,:])\n",
    "\n",
    "#print(delay_rnd_draw.shape)\n",
    "#print(wavelets_rnd_draw.shape)\n",
    "#print(wavelets_rnd_draw)\n",
    "    \n",
    "#calculate median and 90%CI delay\n",
    "median_glitch_delays = np.zeros( (len(psrs), max_obs) )\n",
    "lower90_glitch_delays = np.zeros( (len(psrs), max_obs) )\n",
    "upper90_glitch_delays = np.zeros( (len(psrs), max_obs) )\n",
    "for kk in range(len(psrs)):\n",
    "    for ll in range(psrs[kk].toas.shape[0]):\n",
    "        median_glitch_delays[kk,ll] = np.median(all_glitch_delays[:,kk,ll])\n",
    "        upper90_glitch_delays[kk,ll] = np.percentile(all_glitch_delays[:,kk,ll], 95)\n",
    "        lower90_glitch_delays[kk,ll] = np.percentile(all_glitch_delays[:,kk,ll], 5)\n",
    "        #if kk==0:\n",
    "        #    print(all_glitch_delays[:,kk,ll])\n",
    "\n",
    "##################\n",
    "#injected delays (if explicitly injecting wavelets into data)\n",
    "###################\n",
    "x_glitch_true = {\n",
    "    'Glitch_0_log10_f0':np.log10(6e-8),\n",
    "#    'Glitch_0_log10_h':np.log10(5e-6), #medium amp\n",
    "#    'Glitch_0_log10_h':np.log10(2e-6), #low amp\n",
    "    'Glitch_0_log10_h':np.log10(1e-6), #very low amp\n",
    "    'Glitch_0_phase0':1.0,\n",
    "    'Glitch_0_psr_idx':0.0,\n",
    "    'Glitch_0_t0':2500.0/365.25, #year\n",
    "    'Glitch_0_tau':300.0/365.25, #year\n",
    "}\n",
    "\n",
    "#2wavelet_very_low_amp_not_ell_pol\n",
    "x_gw = {\n",
    "    'wavelet_0_cos_gwtheta':np.cos(np.pi/2),\n",
    "    'wavelet_0_gw_psi':0.0,\n",
    "    'wavelet_0_gwphi':0.0,\n",
    "    'wavelet_0_log10_f0':np.log10(3e-8),\n",
    "    'wavelet_0_log10_h':np.log10(1.25e-6), #low amp\n",
    "    'wavelet_0_log10_h_cross':np.log10(1.25e-6), #low amp\n",
    "    'wavelet_0_phase0':0.0,\n",
    "    'wavelet_0_phase0_cross':0.0,\n",
    "    'wavelet_0_t0':1000.0/365.25, #year\n",
    "    'wavelet_0_tau':200.0/365.25, #year\n",
    "    'wavelet_1_cos_gwtheta':np.cos(np.pi/2),\n",
    "    'wavelet_1_gw_psi':0.0,\n",
    "    'wavelet_1_gwphi':0.0,\n",
    "    'wavelet_1_log10_f0':np.log10(4e-8),\n",
    "    'wavelet_1_log10_h':np.log10(1e-6), #low amp\n",
    "    'wavelet_1_log10_h_cross':np.log10(1e-6), #low amp\n",
    "    'wavelet_1_phase0':2.0,\n",
    "    'wavelet_1_phase0_cross':2.0,\n",
    "    'wavelet_1_t0':1300.0/365.25, #year\n",
    "    'wavelet_1_tau':500.0/365.25, #year\n",
    "}\n",
    "\n",
    "delays_glitch = PTA.get_delay(x_glitch_true)\n",
    "delays_gw = PTA.get_delay(x_gw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306efb9e",
   "metadata": {},
   "source": [
    "## Parabolic injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a86879a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#WNB injected\n",
    "t0 = 6.0*365.25*24*3600 #seconds\n",
    "f0 = 6e-8 #Hz\n",
    "delt = 1.0*365.25*24*3600 #seconds\n",
    "delf = 4e-8 #Hz\n",
    "amplitude = 2e-6\n",
    "wnb_seed = 12345678\n",
    "\n",
    "#inj_plus, inj_cross = WNBSimulator(t, amplitude, t0, f0, delt, delf, wnb_seed)\n",
    "\n",
    "def inj_plus_wnb(t):\n",
    "    inj_plus, inj_cross = WNBSimulator(t, amplitude, t0, f0, delt, delf, wnb_seed)\n",
    "    return inj_plus\n",
    "\n",
    "def inj_cross_wnb(t):\n",
    "    inj_plus, inj_cross = WNBSimulator(t, amplitude, t0, f0, delt, delf, wnb_seed)\n",
    "    return inj_cross\n",
    "\n",
    "#parameters\n",
    "#masses\n",
    "m1 = 1e9 #solar mass\n",
    "m2 = 1e9 #solar mass\n",
    "#impact parameter\n",
    "#b = 180*(m1+m2)\n",
    "b = 60*(m1+m2) #short\n",
    "#pericenter passage time\n",
    "t_pericenter = 55000 #MJD\n",
    "#distance\n",
    "#dist = 15 #Mpc #high amp\n",
    "#dist = 3 #Mpc #higher amp\n",
    "dist = 30 #Mpc #low amp\n",
    "#sky location\n",
    "gw_theta = np.pi/2\n",
    "gw_phi = 3.7 #4.0\n",
    "#polarization (not needed for reconstructions, only skymap)\n",
    "psi = 0.2 #0.0\n",
    "\n",
    "def inj_plus_parabolic(t):\n",
    "    inj_plus, inj_cross = parabolic_signal(t, m1, m2, b, t_pericenter, dist, tref)\n",
    "    return inj_plus\n",
    "\n",
    "def inj_cross_parabolic(t):\n",
    "    inj_plus, inj_cross = parabolic_signal(t, m1, m2, b, t_pericenter, dist, tref)\n",
    "    return inj_cross\n",
    "\n",
    "wnb_gw_delays = []\n",
    "parabolic_gw_delays = []\n",
    "for ii, psr in enumerate(psrs):\n",
    "    # define variable for later use\n",
    "    cosgwtheta, cosgwphi = np.cos(gw_theta), np.cos(gw_phi)\n",
    "    singwtheta, singwphi = np.sin(gw_theta), np.sin(gw_phi)\n",
    "\n",
    "    # unit vectors to GW source\n",
    "    m = np.array([singwphi, -cosgwphi, 0.0])\n",
    "    n = np.array([-cosgwtheta*cosgwphi, -cosgwtheta*singwphi, singwtheta])\n",
    "    omhat = np.array([-singwtheta*cosgwphi, -singwtheta*singwphi, -cosgwtheta])\n",
    "\n",
    "    # pulsar location\n",
    "    ptheta = psr.theta\n",
    "    pphi = psr.phi\n",
    "\n",
    "    # use definition from Sesana et al 2010 and Ellis et al 2012\n",
    "    phat = np.array([np.sin(ptheta)*np.cos(pphi), np.sin(ptheta)*np.sin(pphi),\\\n",
    "            np.cos(ptheta)])\n",
    "\n",
    "    #print(ptheta, pphi, gwtheta, gwphi)\n",
    "\n",
    "    fplus = 0.5 * (np.dot(m, phat)**2 - np.dot(n, phat)**2) / (1+np.dot(omhat, phat))\n",
    "    fcross = (np.dot(m, phat)*np.dot(n, phat)) / (1 + np.dot(omhat, phat))\n",
    "\n",
    "    # get toas from pulsar object\n",
    "    toas = psr.toas - tref\n",
    "    #print(toas)\n",
    "    ################## WNB\n",
    "\n",
    "    # define residuals: rplus and rcross\n",
    "    rplus_wnb = inj_plus_wnb(toas)\n",
    "    rcross_wnb = inj_cross_wnb(toas)\n",
    "\n",
    "    # residuals\n",
    "    res_wnb = -fplus*rplus_wnb - fcross*rcross_wnb\n",
    "\n",
    "    wnb_gw_delays.append( np.array(res_wnb))\n",
    "    \n",
    "    ################### Parabolic\n",
    "    \n",
    "    # define residuals: rplus and rcross\n",
    "    rplus_parabolic = inj_plus_parabolic(toas)\n",
    "    rcross_parabolic = inj_cross_parabolic(toas)\n",
    "\n",
    "    # residuals\n",
    "    res_parabolic = -fplus*rplus_parabolic - fcross*rcross_parabolic\n",
    "    \n",
    "    #remove quadratic fit\n",
    "    pp = np.polyfit(np.array(toas, dtype=np.double), np.array(res_parabolic, dtype=np.double), 2)\n",
    "    res_parabolic = res_parabolic - pp[0]*toas**2 -pp[1]*toas - pp[2]\n",
    "\n",
    "    if no_burst:\n",
    "        res_parabolic = 0*res_parabolic\n",
    "    parabolic_gw_delays.append( np.array(res_parabolic))\n",
    "\n",
    "print(upper90_glitch_delays[0,:]*1e6)\n",
    "\n",
    "print(wnb_gw_delays[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f6195",
   "metadata": {},
   "source": [
    "## Calculating match statistic between injection and mean signal reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a818b3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "#IF VARYING ANY NOISE: -> PASS IN PARAMS DICTIONARY\n",
    "###\n",
    "S_matrix = QB_mcmc.get_similarity_matrix(PTA, psrs, [median_delays, parabolic_gw_delays], noise_param_dict = None)\n",
    "\n",
    "M_matrix = QB_mcmc.get_match_matrix(PTA, psrs, [median_delays, parabolic_gw_delays], noise_param_dict=noise_params)\n",
    "\n",
    "Match = M_matrix[1,0]\n",
    "SNR_inj = np.sqrt(S_matrix[1,1])\n",
    "SNR_rec = np.sqrt(S_matrix[0,0])\n",
    "\n",
    "print(S_matrix)\n",
    "print(M_matrix)\n",
    "print(\"Injected SNR: \", SNR_inj)\n",
    "print(\"Recovered SNR: \", SNR_rec)\n",
    "print(\"Match between injected and recovered waveform: \", Match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aeb3df",
   "metadata": {},
   "source": [
    "# Main reconstruction plotting loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681baed4",
   "metadata": {},
   "source": [
    "# 1) For realistic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eff41b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_path = '/home/user/path_to/plot_folder'\n",
    "os.makedirs(plot_path, exist_ok = True)\n",
    "#print(wnb_gw_delays[0])\n",
    "for idx in range(len(psrs)):\n",
    "\n",
    "    plt.close()\n",
    "    print('plotting: ', psrs[idx].name)\n",
    "\n",
    "    sr=gp(psrs,PTA,chain=samples[0,burnin:,2:])\n",
    "    #print(sr.gp_types)\n",
    "\n",
    "    sec_to_day = 24*3600\n",
    "    psrname = psrs[idx].name\n",
    "\n",
    "    # parameter indices to pull from chain. Change `size` flag for more or less.\n",
    "    idxs = np.random.randint(0, sr.chain.shape[0],size=30)\n",
    "    \n",
    "    ########## GP models to subtract out of residuals ############\n",
    "    \n",
    "#     linear_timing_gp = np.array([sr.reconstruct_signal(gp_type='timing', idx=idx)[psrname]\n",
    "#                     for idx in idxs])\n",
    "#     timing_piece_gp = np.array([sr.reconstruct_signal(gp_type=psrs[idx].fitpars[idx], idx=indx)[psrname]\n",
    "#                     for idx in idxs])\n",
    "#     com_rn_gp = np.array([sr.reconstruct_signal(gp_type='rn', idx=idx)[psrname]\n",
    "#                     for idx in idxs])\n",
    "#     rn_gp = np.array([sr.reconstruct_signal(gp_type='red_noise', idx=idx)[psrname]\n",
    "#                     for idx in idxs])\n",
    "    all_gp = np.array([sr.reconstruct_signal(gp_type='all', idx=idx)[psrname]\n",
    "                    for idx in idxs])\n",
    "#     linear_timing_gp_mean = np.mean(linear_timing_gp,axis=0)\n",
    "#     timing_piece_gp_mean = np.mean(timing_piece_gp,axis=0)\n",
    "#     com_rn_gp_mean = np.median(com_rn_gp,axis=0)\n",
    "#     rn_gp_mean = np.median(rn_gp,axis=0)\n",
    "    all_gp_mean = np.median(all_gp,axis=0)\n",
    "    \n",
    "#     #upper 90%\n",
    "#     linear_timing_gp_upper = np.percentile(linear_timing_gp, 95,axis=0)\n",
    "#     rn_gp_upper = np.percentile(rn_gp_mean, 95, axis=0)\n",
    "#     com_rn_gp_upper = np.percentile(com_rn_gp, 95,axis=0)\n",
    "    all_gp_upper = np.percentile(all_gp, 95,axis=0)\n",
    "    \n",
    "    #lower 90%\n",
    "#     linear_timing_gp_lower = np.percentile(linear_timing_gp, 5,axis=0)\n",
    "#     rn_gp_lower = np.percentile(rn_gp_mean, 5, axis=0)\n",
    "#     com_rn_gp_lower = np.percentile(com_rn_gp, 5,axis=0)\n",
    "    all_gp_lower = np.percentile(all_gp, 5,axis=0)\n",
    "    \n",
    "    ############ End of models to subtract out ###############   \n",
    "    \n",
    "    ###############################\n",
    "    #\n",
    "    #EPOCH averaging w/ la_forge\n",
    "    #\n",
    "    ###############################\n",
    "\n",
    "    sec_to_day = 24*3600\n",
    "\n",
    "    resids, msks = epoch_ave_resid(psrs[idx])  \n",
    "    print('resids keys 1:', resids.keys())\n",
    "    resids_corr, msks_corr = epoch_ave_resid(psrs[idx], correction=all_gp_mean) #+ parabolic_gw_delays[idx]) #subtracting the median RN and Burst\n",
    "    print('resids_corr keys:', resids_corr.keys())\n",
    "    \n",
    "    psrCorr_AveTOAs = resids_corr[list(resids_corr.keys())[0]][:,0]\n",
    "    psrCorr_AveResids = resids_corr[list(resids_corr.keys())[0]][:,1]\n",
    "    psrCorr_AveResid_err = resids_corr[list(resids_corr.keys())[0]][:,2]\n",
    "    \n",
    "    psr_AveTOAs = resids[list(resids.keys())[0]][:,0]\n",
    "    psr_AveResids = resids[list(resids.keys())[0]][:,1]\n",
    "    psr_AveResid_err = resids[list(resids.keys())[0]][:,2]\n",
    "    ###############################\n",
    "    #\n",
    "    #END OF EPOCH averaging\n",
    "    #\n",
    "    ###############################\n",
    "    \n",
    "    '''BEGIN PLOTTING'''\n",
    "\n",
    "    \"\"\"Plot GP models individually. Good for visually checking model covariances, if applicable. \"\"\"\n",
    "    #plt.plot(psr.toas/sec_to_day,linear_timing_gp_mean*1e6, label='Timing', ls='', marker='x')\n",
    "    #plt.plot(psr.toas/sec_to_day,timing_piece_gp_mean*1e6, label=psrs[0].fitpars[idx], ls='', marker='x')\n",
    "    #plt.plot(psr.toas/sec_to_day,com_rn_gp_mean*1e6, label='Com RN')\n",
    "    #plt.plot(psr.toas/sec_to_day,rn_gp_mean*1e6, label='Individual RN')\n",
    "    #plt.plot(psrs[idx].toas/sec_to_day,all_gp_mean*1e6, label='GP All', ls='', marker='x')\n",
    "\n",
    "    #plt.legend()\n",
    "    \n",
    "    fig, ax1 = plt.subplots(num=idx, figsize=(9,6))\n",
    "\n",
    "\n",
    "    \"\"\"Plot Resids (not epoch averaged) - RN GP and Timing GP. Typically used for simple simulations.\"\"\"\n",
    "#     plt.errorbar(psrs[idx].toas/86400, (psrs[idx].residuals-all_gp_mean)*1e6, yerr = (psrs[idx].toaerrs-all_gp_mean)*1e6, \n",
    "#                  alpha = 0.5, ls = '', marker = '.')\n",
    "\n",
    "    \"\"\"Plot epoch averaged timing residuals - RN GP and Timing GP. Typically used for realistic simulations and/or real data.\"\"\"\n",
    "    plt.errorbar(psrCorr_AveTOAs/sec_to_day,\n",
    "                 psrCorr_AveResids*1e6,\n",
    "                 yerr=psrCorr_AveResid_err*1e6, fmt='x', label='Epoch-averaged Resids - RN and Timing ({})'.format(list(resids_corr.keys())[0]),\n",
    "                 color=spec_colors[\"data\"], alpha=0.5, markeredgewidth=1, elinewidth=1, capsize=5)\n",
    "\n",
    "    #res_model = pta.get_delay(xx)[idx]\n",
    "    #res_model = pta.get_delay(samples_burned[10000,1:1+max_wavelets*8])[idx]\n",
    "    #for kk in range(100):\n",
    "    #    plt.plot(t,all_delays[kk,idx,:]*1e6, color=\"r\", alpha=0.1)\n",
    "    \n",
    "    #plt.plot(t,median_delays[idx,:]*1e6, color=\"r\", alpha=1.0, ls='--')\n",
    "    \n",
    "    \"\"\"Plot reconstructed GW wavelet signal\"\"\"\n",
    "    ax1.fill_between(psrs[idx].toas/sec_to_day, lower90_delays[idx,:psrs[idx].toas.shape[0]]*1e6, upper90_delays[idx,:psrs[idx].toas.shape[0]]*1e6, color=spec_colors[\"GW_rec\"],\n",
    "                     alpha=0.3, label='Reconstructed GW signal (90% CI)')\n",
    "    \n",
    "    \"\"\"Plot reconstructed transient noise\"\"\"\n",
    "    ax1.fill_between(psrs[idx].toas/sec_to_day, lower90_glitch_delays[idx,:psrs[idx].toas.shape[0]]*1e6, upper90_glitch_delays[idx,:psrs[idx].toas.shape[0]]*1e6,\n",
    "                     color=spec_colors[\"glitch_rec\"],\n",
    "                     alpha=0.3, label='Reconstructed transient noise (90% CI)')\n",
    "    \n",
    "    \"\"\"Plot mean reconstructed transient noise\"\"\"\n",
    "    ax1.plot(psrs[idx].toas/sec_to_day, median_glitch_delays[idx,:psrs[idx].toas.shape[0]]*1e6, color=spec_colors[\"glitch_rec\"],\n",
    "                 alpha=1.0, ls='-', lw=1, label='Reconstructed transient noise (median)')\n",
    "    \n",
    "    \"\"\"Plot mean GW signal wavelet reconstruction\"\"\"\n",
    "    ax1.plot(psrs[idx].toas/sec_to_day, median_delays[idx,:psrs[idx].toas.shape[0]]*1e6, color=spec_colors[\"GW_rec\"],\n",
    "                     alpha=1.0, ls='-', lw=1, label='Reconstructed GW signal (median)')\n",
    "    \n",
    "    '''PLOTS FOR SIMULATED SIGNALS'''\n",
    "    \n",
    "    \"\"\"Plot injected GW signal (if injected exact wavelet waveforms)\"\"\"\n",
    "    #ax1.plot(psrs[idx].toas/86400, delays_gw[idx]*1e6, color=spec_colors['GW_inj'], ls='--', label='Injected GW')\n",
    "    \n",
    "    \"\"\"Plot injected transient noise (if injected exact transient noise wavelets)\"\"\"\n",
    "    #plt.plot(t, delays_glitch[idx]*1e6, color=spec_colors['glitch_inj'], ls='--', label='Injected glitch')\n",
    "    \n",
    "    \"\"\"Plot injected GW signal (if not using exact waveform)\"\"\"\n",
    "    plt.plot(psrs[idx].toas/sec_to_day, parabolic_gw_delays[idx]*1e6, color='xkcd:purple', ls='--', label='Injected GW signal')\n",
    "    \n",
    "    '''PLOTS FOR SIMULATED SIGNALS'''\n",
    "    \n",
    "    \"\"\"Plot all GP models\"\"\"\n",
    "#     plt.plot(psrs[idx].toas/sec_to_day, all_gp_mean*1e6, color='xkcd:orange', ls='-', lw=1, label='All GP (median)')\n",
    "\n",
    "    \"\"\"Plot 90% CI for all GP models\"\"\"\n",
    "#     plt.fill_between(psrs[idx].toas/sec_to_day, all_gp_lower*1e6, all_gp_upper*1e6, color='xkcd:orange',\n",
    "#                     alpha=0.3, label='All GP median (90% CI)')\n",
    "\n",
    "    \"\"\"Plot GW reconstructions for randomly drawn samples\"\"\"\n",
    "    #plt.plot(t, delay_rnd_draw[idx,:psrs[idx].toas.shape[0]]*1e6, color=\"xkcd:purple\", label='Reconstructed random draw')\n",
    "    #for ww in range(wavelets_rnd_draw.shape[0]):\n",
    "    #    plt.plot(t, wavelets_rnd_draw[ww,idx,:psrs[idx].toas.shape[0]]*1e6-(ww+1)*5.0, color=\"xkcd:purple\", ls='--',\n",
    "    #             label=\"wavelet #{0}\".format(ww))\n",
    "    \n",
    "    \"\"\"\"\"\"\n",
    "    #plt.plot(t,lower90_delays[idx,:psrs[idx].toas.shape[0]]*1e6, color=\"b\", alpha=1.0, ls='--')\n",
    "    #plt.plot(t,upper90_delays[idx,:psrs[idx].toas.shape[0]]*1e6, color=\"b\", alpha=1.0, ls='--')\n",
    "\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    # sort both labels and handles by labels\n",
    "    labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "    ax1.legend(handles, labels, loc=1)\n",
    "    #ax1.legend(loc=1)\n",
    "    #plt.ylim((-5.5,5.5))\n",
    "    print('Min, max resids_corr error: ', np.min(psrCorr_AveResids)*2e6, np.max(psrCorr_AveResids)*2e6)\n",
    "    ax1.set_ylim(np.min(psrCorr_AveResids) - 2*(np.abs(np.max(psrCorr_AveResid_err)))*1e6, (np.max(psrCorr_AveResids) + 2*np.abs(np.max(psrCorr_AveResid_err)))*1e6)\n",
    "    #ax1.set_ylim(-0.5, 2.0)\n",
    "    #plt.ylim((-2.0,2.0))\n",
    "    ax1.set_ylabel(\"Residual [$\\mu$s]\")\n",
    "    ax1.set_xlabel('Time [MJD]')\n",
    "    plt.xlim((psrCorr_AveTOAs.min()/sec_to_day-50,psrCorr_AveTOAs.max()/sec_to_day+50))\n",
    "    ax1.set_title(\"Pulsar {}\".format(psrs[idx].name))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "#     plt.savefig(plot_path + \"{}_Waveform_reconstruction.png\".format(psrs[idx].name), dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e902cf3b",
   "metadata": {},
   "source": [
    "# 2) For simple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b9fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_path = '/home/user/path_to/plot_folder'\n",
    "os.makedirs(plot_path, exist_ok = True)\n",
    "#print(wnb_gw_delays[0])\n",
    "for idx in range(len(psrs)):\n",
    "\n",
    "    plt.close()\n",
    "    print('plotting: ', psrs[idx].name)\n",
    "\n",
    "    sr=gp(psrs,PTA,chain=samples[0,burnin:,2:])\n",
    "    #print(sr.gp_types)\n",
    "\n",
    "    sec_to_day = 24*3600\n",
    "    psrname = psrs[idx].name\n",
    "\n",
    "    # parameter indices to pull from chain. Change `size` flag for more or less.\n",
    "    idxs = np.random.randint(0, sr.chain.shape[0],size=30)\n",
    "    \n",
    "    ########## GP models to subtract out of residuals ############\n",
    "    \n",
    "#     linear_timing_gp = np.array([sr.reconstruct_signal(gp_type='timing', idx=idx)[psrname]\n",
    "#                     for idx in idxs])\n",
    "#     timing_piece_gp = np.array([sr.reconstruct_signal(gp_type=psrs[idx].fitpars[idx], idx=indx)[psrname]\n",
    "#                     for idx in idxs])\n",
    "#     com_rn_gp = np.array([sr.reconstruct_signal(gp_type='rn', idx=idx)[psrname]\n",
    "#                     for idx in idxs])\n",
    "#     rn_gp = np.array([sr.reconstruct_signal(gp_type='red_noise', idx=idx)[psrname]\n",
    "#                     for idx in idxs])\n",
    "    all_gp = np.array([sr.reconstruct_signal(gp_type='all', idx=idx)[psrname]\n",
    "                    for idx in idxs])\n",
    "#     linear_timing_gp_mean = np.mean(linear_timing_gp,axis=0)\n",
    "#     timing_piece_gp_mean = np.mean(timing_piece_gp,axis=0)\n",
    "#     com_rn_gp_mean = np.median(com_rn_gp,axis=0)\n",
    "#     rn_gp_mean = np.median(rn_gp,axis=0)\n",
    "    all_gp_mean = np.median(all_gp,axis=0)\n",
    "    \n",
    "#     #upper 90%\n",
    "#     linear_timing_gp_upper = np.percentile(linear_timing_gp, 95,axis=0)\n",
    "#     rn_gp_upper = np.percentile(rn_gp_mean, 95, axis=0)\n",
    "#     com_rn_gp_upper = np.percentile(com_rn_gp, 95,axis=0)\n",
    "    all_gp_upper = np.percentile(all_gp, 95,axis=0)\n",
    "    \n",
    "    #lower 90%\n",
    "#     linear_timing_gp_lower = np.percentile(linear_timing_gp, 5,axis=0)\n",
    "#     rn_gp_lower = np.percentile(rn_gp_mean, 5, axis=0)\n",
    "#     com_rn_gp_lower = np.percentile(com_rn_gp, 5,axis=0)\n",
    "    all_gp_lower = np.percentile(all_gp, 5,axis=0)\n",
    "    \n",
    "    ############ End of models to subtract out ###############   \n",
    "    \n",
    "    ###############################\n",
    "    #\n",
    "    #EPOCH averaging w/ la_forge\n",
    "    #\n",
    "    ###############################\n",
    "\n",
    "    sec_to_day = 24*3600\n",
    "\n",
    "    resids, msks = epoch_ave_resid(psrs[idx])  \n",
    "    print('resids keys 1:', resids.keys())\n",
    "    resids_corr, msks_corr = epoch_ave_resid(psrs[idx], correction=all_gp_mean) #+ parabolic_gw_delays[idx]) #subtracting the median RN and Burst\n",
    "    print('resids_corr keys:', resids_corr.keys())\n",
    "    \n",
    "    psrCorr_AveTOAs = resids_corr[list(resids_corr.keys())[0]][:,0]\n",
    "    psrCorr_AveResids = resids_corr[list(resids_corr.keys())[0]][:,1]\n",
    "    psrCorr_AveResid_err = resids_corr[list(resids_corr.keys())[0]][:,2]\n",
    "    \n",
    "    psr_AveTOAs = resids[list(resids.keys())[0]][:,0]\n",
    "    psr_AveResids = resids[list(resids.keys())[0]][:,1]\n",
    "    psr_AveResid_err = resids[list(resids.keys())[0]][:,2]\n",
    "    ###############################\n",
    "    #\n",
    "    #END OF EPOCH averaging\n",
    "    #\n",
    "    ###############################\n",
    "    \n",
    "    '''BEGIN PLOTTING'''\n",
    "\n",
    "    \"\"\"Plot GP models individually. Good for visually checking model covariances, if applicable. \"\"\"\n",
    "    #plt.plot(psr.toas/sec_to_day,linear_timing_gp_mean*1e6, label='Timing', ls='', marker='x')\n",
    "    #plt.plot(psr.toas/sec_to_day,timing_piece_gp_mean*1e6, label=psrs[0].fitpars[idx], ls='', marker='x')\n",
    "    #plt.plot(psr.toas/sec_to_day,com_rn_gp_mean*1e6, label='Com RN')\n",
    "    #plt.plot(psr.toas/sec_to_day,rn_gp_mean*1e6, label='Individual RN')\n",
    "    #plt.plot(psrs[idx].toas/sec_to_day,all_gp_mean*1e6, label='GP All', ls='', marker='x')\n",
    "\n",
    "    #plt.legend()\n",
    "    \n",
    "    fig, ax1 = plt.subplots(num=idx, figsize=(9,6))\n",
    "\n",
    "\n",
    "    \"\"\"Plot Resids (not epoch averaged) - RN GP and Timing GP. Typically used for simple simulations.\"\"\"\n",
    "    plt.errorbar(psrs[idx].toas/86400, (psrs[idx].residuals-all_gp_mean)*1e6, yerr = (psrs[idx].toaerrs-all_gp_mean)*1e6, \n",
    "                 alpha = 0.5, ls = '', marker = '.')\n",
    "\n",
    "    \"\"\"Plot epoch averaged timing residuals - RN GP and Timing GP. Typically used for realistic simulations or real data.\"\"\"\n",
    "#     plt.errorbar(psrCorr_AveTOAs/sec_to_day,\n",
    "#                  psrCorr_AveResids*1e6,\n",
    "#                  yerr=psrCorr_AveResid_err*1e6, fmt='x', label='Epoch-averaged Resids - RN and Timing ({})'.format(list(resids_corr.keys())[0]),\n",
    "#                  color=spec_colors[\"data\"], alpha=0.5, markeredgewidth=1, elinewidth=1, capsize=5)\n",
    "\n",
    "    #res_model = pta.get_delay(xx)[idx]\n",
    "    #res_model = pta.get_delay(samples_burned[10000,1:1+max_wavelets*8])[idx]\n",
    "    #for kk in range(100):\n",
    "    #    plt.plot(t,all_delays[kk,idx,:]*1e6, color=\"r\", alpha=0.1)\n",
    "    \n",
    "    #plt.plot(t,median_delays[idx,:]*1e6, color=\"r\", alpha=1.0, ls='--')\n",
    "    \n",
    "    \"\"\"Plot reconstructed GW wavelet signal\"\"\"\n",
    "    ax1.fill_between(psrs[idx].toas/sec_to_day, lower90_delays[idx,:psrs[idx].toas.shape[0]]*1e6, upper90_delays[idx,:psrs[idx].toas.shape[0]]*1e6, color=spec_colors[\"GW_rec\"],\n",
    "                     alpha=0.3, label='Reconstructed GW signal (90% CI)')\n",
    "    \n",
    "    \"\"\"Plot reconstructed transient noise\"\"\"\n",
    "    ax1.fill_between(psrs[idx].toas/sec_to_day, lower90_glitch_delays[idx,:psrs[idx].toas.shape[0]]*1e6, upper90_glitch_delays[idx,:psrs[idx].toas.shape[0]]*1e6,\n",
    "                     color=spec_colors[\"glitch_rec\"],\n",
    "                     alpha=0.3, label='Reconstructed transient noise (90% CI)')\n",
    "    \n",
    "    \"\"\"Plot mean reconstructed transient noise\"\"\"\n",
    "    ax1.plot(psrs[idx].toas/sec_to_day, median_glitch_delays[idx,:psrs[idx].toas.shape[0]]*1e6, color=spec_colors[\"glitch_rec\"],\n",
    "                 alpha=1.0, ls='-', lw=1, label='Reconstructed transient noise (median)')\n",
    "    \n",
    "    \"\"\"Plot mean GW signal wavelet reconstruction\"\"\"\n",
    "    ax1.plot(psrs[idx].toas/sec_to_day, median_delays[idx,:psrs[idx].toas.shape[0]]*1e6, color=spec_colors[\"GW_rec\"],\n",
    "                     alpha=1.0, ls='-', lw=1, label='Reconstructed GW signal (median)')\n",
    "    \n",
    "    '''PLOTS FOR SIMULATED SIGNALS'''\n",
    "    \n",
    "    \"\"\"Plot injected GW signal (if injected exact wavelet waveforms)\"\"\"\n",
    "    #ax1.plot(psrs[idx].toas/86400, delays_gw[idx]*1e6, color=spec_colors['GW_inj'], ls='--', label='Injected GW')\n",
    "    \n",
    "    \"\"\"Plot injected transient noise (if injected exact transient noise wavelets)\"\"\"\n",
    "    #plt.plot(t, delays_glitch[idx]*1e6, color=spec_colors['glitch_inj'], ls='--', label='Injected glitch')\n",
    "    \n",
    "    \"\"\"Plot injected GW signal (if not using exact waveform)\"\"\"\n",
    "    plt.plot(psrs[idx].toas/sec_to_day, parabolic_gw_delays[idx]*1e6, color='xkcd:purple', ls='--', label='Injected GW signal')\n",
    "    \n",
    "    '''PLOTS FOR SIMULATED SIGNALS'''\n",
    "    \n",
    "    \"\"\"Plot all GP models\"\"\"\n",
    "#     plt.plot(psrs[idx].toas/sec_to_day, all_gp_mean*1e6, color='xkcd:orange', ls='-', lw=1, label='All GP (median)')\n",
    "\n",
    "    \"\"\"Plot 90% CI for all GP models\"\"\"\n",
    "#     plt.fill_between(psrs[idx].toas/sec_to_day, all_gp_lower*1e6, all_gp_upper*1e6, color='xkcd:orange',\n",
    "#                     alpha=0.3, label='All GP median (90% CI)')\n",
    "\n",
    "    \"\"\"Plot GW reconstructions for randomly drawn samples\"\"\"\n",
    "    #plt.plot(t, delay_rnd_draw[idx,:psrs[idx].toas.shape[0]]*1e6, color=\"xkcd:purple\", label='Reconstructed random draw')\n",
    "    #for ww in range(wavelets_rnd_draw.shape[0]):\n",
    "    #    plt.plot(t, wavelets_rnd_draw[ww,idx,:psrs[idx].toas.shape[0]]*1e6-(ww+1)*5.0, color=\"xkcd:purple\", ls='--',\n",
    "    #             label=\"wavelet #{0}\".format(ww))\n",
    "    \n",
    "    \"\"\"\"\"\"\n",
    "    #plt.plot(t,lower90_delays[idx,:psrs[idx].toas.shape[0]]*1e6, color=\"b\", alpha=1.0, ls='--')\n",
    "    #plt.plot(t,upper90_delays[idx,:psrs[idx].toas.shape[0]]*1e6, color=\"b\", alpha=1.0, ls='--')\n",
    "\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    # sort both labels and handles by labels\n",
    "    labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "    ax1.legend(handles, labels, loc=1)\n",
    "    #ax1.legend(loc=1)\n",
    "    #plt.ylim((-5.5,5.5))\n",
    "    print('Min, max resids_corr error: ', np.min(psrCorr_AveResids)*2e6, np.max(psrCorr_AveResids)*2e6)\n",
    "    ax1.set_ylim(np.min(psrCorr_AveResids) - 2*(np.abs(np.max(psrCorr_AveResid_err)))*1e6, (np.max(psrCorr_AveResids) + 2*np.abs(np.max(psrCorr_AveResid_err)))*1e6)\n",
    "    #ax1.set_ylim(-0.5, 2.0)\n",
    "    #plt.ylim((-2.0,2.0))\n",
    "    ax1.set_ylabel(\"Residual [$\\mu$s]\")\n",
    "    ax1.set_xlabel('Time [MJD]')\n",
    "    plt.xlim((psrCorr_AveTOAs.min()/sec_to_day-50,psrCorr_AveTOAs.max()/sec_to_day+50))\n",
    "    ax1.set_title(\"Pulsar {}\".format(psrs[idx].name))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "#     plt.savefig(plot_path + \"{}_Waveform_reconstruction.png\".format(psrs[idx].name), dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d2d738",
   "metadata": {},
   "source": [
    "# Creating Skymap for burst reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc7ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "#masses\n",
    "m1 = 1e9 #solar mass\n",
    "m2 = 1e9 #solar mass\n",
    "#impact parameter\n",
    "#b = 180*(m1+m2)\n",
    "b = 60*(m1+m2) #short\n",
    "#pericenter passage time\n",
    "t_pericenter = 55000 #MJD\n",
    "#distance\n",
    "#dist = 15 #Mpc #high amp\n",
    "#dist = 3 #Mpc #higher amp\n",
    "dist = 60 #Mpc #low amp\n",
    "#sky location\n",
    "gw_theta = np.pi/2\n",
    "# gw_phi = 4.0 #(normal sky location)\n",
    "gw_phi = 3.7 #(sky shifted location)\n",
    "#polarization #(not needed for reconstructions, only skymap)\n",
    "# psi = 0.0\n",
    "psi = -0.3 #(sky shifted sky location polarization)\n",
    "#Function for getting antenna response\n",
    "def burst_response(burst_theta, burst_phi, burst_pol, skymap_nside, skypix):\n",
    "    '''\n",
    "    Returns the response of a pulsar in a certain skylocation based on the GW burst parameters\n",
    "    '''\n",
    "    #print(burst_theta, burst_phi, burst_pol, skymap_nside, skypix)\n",
    "    pos = hp.pix2vec(skymap_nside, skypix,)\n",
    "    \n",
    "    apc = utils.create_gw_antenna_pattern(pos, burst_theta, burst_phi)\n",
    "    fp, fc = apc[0], apc[1]\n",
    "    t_temp = psrs[0].toas-tref\n",
    "    #print(t_temp)\n",
    "    #plus, cross rotated metric perturbation\n",
    "#     plus_metric_p, cross_metric_p = parabolic_signal(t_temp, m1, m2, b, t_pericenter, dist, tref)\n",
    "#     pol = -fp*plus_metric_p - fc*cross_metric_p\n",
    "    \n",
    "    pol = -fp*np.cos(2*burst_pol) - fc*np.sin(2*burst_pol)\n",
    "    \n",
    "    return pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8ce06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#param samples from chain\n",
    "burnin = int(len(log_likelihood[n_chain])*0.25)\n",
    "gw_thetas = np.arccos(samples[0,burnin:,2+PTA.param_names.index(\"wavelet_0_cos_gwtheta\")])\n",
    "gw_psis = samples[0,burnin:,2+PTA.param_names.index(\"wavelet_0_gw_psi\")]\n",
    "gw_phis = samples[0,burnin:,2+PTA.param_names.index(\"wavelet_0_gwphi\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750cd50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "\n",
    "NSIDE=40\n",
    "npix = hp.nside2npix(NSIDE)\n",
    "# print(npix)\n",
    "\n",
    "#get hp indices for each sample\n",
    "indices = hp.ang2pix(NSIDE, gw_thetas, gw_phis)\n",
    "\n",
    "#get counts for each pixel\n",
    "idx, counts = np.unique(indices, return_counts=True)\n",
    "\n",
    "#convert counts to PDF\n",
    "sky_pdf = counts/np.sum(counts)/hp.nside2pixarea(NSIDE)\n",
    "\n",
    "# print(np.sum(counts))\n",
    "# print(sky_pdf)\n",
    "# print(np.max(sky_pdf))\n",
    "\n",
    "# fill the array\n",
    "skymap = np.zeros(npix)\n",
    "skymap[idx] = sky_pdf\n",
    "\n",
    "COORD = None\n",
    "CMAP = 'gist_earth'\n",
    "# CMAP = 'jet_r'\n",
    "# CMAP = 'jet'\n",
    "#Burst sky location\n",
    "gw_theta = np.pi/2\n",
    "gw_phi = 5.0\n",
    "\n",
    "#Burst polarization|angle\n",
    "burst_pol_angle = np.pi-0.3\n",
    "\n",
    "# Get antenna pattern at each pixel\n",
    "\n",
    "#Comment out if plotting burst localization from chain\n",
    "# for skypix_idx, skypix_val in enumerate(skymap):\n",
    "#     #print(skypix_idx)\n",
    "#     skymap[skypix_idx] = burst_response(gw_theta, gw_phi, burst_pol_angle, skymap_nside = NSIDE, skypix=skypix_idx)\n",
    "\n",
    "print(skymap)\n",
    "hp.mollview(skymap, title='', cbar=True, coord=COORD, cmap=CMAP, rot=(-90,-0,0), unit = 'Normalized antenna response')\n",
    "# hp.orthview(np.log(skymap+0.01), title='', half_sky=False, rot=(-30,-0,0), cbar=True, unit = 'Normalized Intensity')\n",
    "# hp.orthview(skymap, title='', half_sky=False, rot=(80,-0.0), cbar=True, unit = 'Normalized Intensity', coord=COORD, cmap=CMAP)\n",
    "#hp.mollview(skymap, title='', cbar=False)\n",
    "hp.graticule(color='white')\n",
    "\n",
    "#pulsar locations\n",
    "tspan0 = enterprise_extensions.model_utils.get_tspan([psrs[0]]) / (365.25*24*3600)\n",
    "if tspan0 < 10:\n",
    "    hp.projscatter(psrs[0].theta, psrs[0].phi, marker='*', s=110/(t0_max-tspan0), linewidth=2, color='xkcd:blue',\n",
    "                   label='Pulsars < 10 year Tspan', coord=COORD)\n",
    "else:\n",
    "    hp.projscatter(psrs[0].theta, psrs[0].phi, marker='*', s=3/(t0_max-tspan0), linewidth=2, color='xkcd:red',\n",
    "                       label='Pulsars > 10 year Tspan', coord=COORD)\n",
    "tspan_counter = 0\n",
    "for p in psrs[1:]:\n",
    "    tspan = enterprise_extensions.model_utils.get_tspan([p]) / (365.25*24*3600)\n",
    "    print( tspan )\n",
    "    if tspan < 10:\n",
    "    #if p.name=='J0613-0200':\n",
    "    #if p.name=='J1600-3053':\n",
    "#     if p.name=='J1455-3330':\n",
    "#     #if p.name=='J1747-4036':\n",
    "#     #if p.name=='J1909-3744':\n",
    "#     #if p.name==None:\n",
    "#         print('yeah')   \n",
    "        while(tspan_counter == 0):\n",
    "            tspan_counter += 1\n",
    "            hp.projscatter(p.theta, p.phi, marker='*', s=70/(t0_max-tspan), linewidth=2, color='xkcd:blue', label = 'Pulsars < 10 year Tspan', coord=COORD)\n",
    "        hp.projscatter(p.theta, p.phi, marker='*', s=70/(t0_max-tspan), linewidth=2, color='xkcd:blue', coord=COORD)\n",
    "    else:\n",
    "        hp.projscatter(p.theta, p.phi, marker='*', s=3/(t0_max-tspan), linewidth=2, color='xkcd:red', coord=COORD)\n",
    "\n",
    "#injected location\n",
    "hp.projscatter(gw_theta, gw_phi, marker=\"^\", s = 50, facecolor='none',\n",
    "              linewidth=2, color='xkcd:yellow', label='GW source', zorder=3)\n",
    "# hp.projscatter(np.cos(-0.7), 5.0, marker=\"^\", s = 50, facecolor='none',\n",
    "#               linewidth=2, color='xkcd:orange', label='Peak?', zorder=3)\n",
    "\n",
    "#spt.healpix_heatmap(skymap, cmap='PuOr', norm=norm)\n",
    "#plt.colorbar(orientation='horizontal', pad=0.05)\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"/home/reyna/BayesHopperBurst/QuickBurst/15_year_A4Cast/Plots/Paper_Plots/60Mpc_RN/fullPTA/skyshifted/skymap_antenna_response.pdf\", dpi=600)\n",
    "plt.show()\n",
    "#plt.savefig(\"Results/Plots/skymap_worst_case_scenario_orth_psr0.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12579d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "\n",
    "NSIDE=40\n",
    "npix = hp.nside2npix(NSIDE)\n",
    "# print(npix)\n",
    "\n",
    "#get hp indices for each sample\n",
    "indices = hp.ang2pix(NSIDE, gw_thetas, gw_phis)\n",
    "\n",
    "#get counts for each pixel\n",
    "idx, counts = np.unique(indices, return_counts=True)\n",
    "\n",
    "#convert counts to PDF\n",
    "sky_pdf = counts/np.sum(counts)/hp.nside2pixarea(NSIDE)\n",
    "\n",
    "# print(np.sum(counts))\n",
    "# print(sky_pdf)\n",
    "# print(np.max(sky_pdf))\n",
    "\n",
    "# fill the array\n",
    "skymap = np.zeros(npix)\n",
    "skymap[idx] = sky_pdf\n",
    "\n",
    "COORD = None\n",
    "# CMAP = 'jet'\n",
    "# CMAP = 'jet_r'\n",
    "CMAP = 'gist_earth'\n",
    "\n",
    "#Burst sky location\n",
    "gw_theta = np.pi/2\n",
    "gw_phi = 5.0\n",
    "\n",
    "#Burst polarization|\n",
    "burst_pol_angle = -0.3\n",
    "\n",
    "# Get antenna pattern at each pixel\n",
    "for skypix_idx, skypix_val in enumerate(skymap):\n",
    "    #print(skypix_idx)\n",
    "    skymap[skypix_idx] = burst_response(gw_theta, gw_phi, burst_pol_angle, skymap_nside = NSIDE, skypix=skypix_idx)\n",
    "\n",
    "print(skymap)\n",
    "hp.mollview(skymap, title='', cbar=False, coord=COORD, cmap=CMAP, rot=(-30,-0,0))\n",
    "#hp.orthview(np.log(skymap+0.01), title='', half_sky=False, rot=(-30,-0,0), cbar=False)\n",
    "#hp.orthview(skymap, title='', half_sky=False, rot=(60,-20,0), cbar=False, coord=COORD, cmap=CMAP)\n",
    "#hp.mollview(skymap, title='', cbar=False)\n",
    "hp.graticule(color='white')\n",
    "\n",
    "#pulsar locations\n",
    "tspan0 = enterprise_extensions.model_utils.get_tspan([psrs[0]]) / (365.25*24*3600)\n",
    "hp.projscatter(psrs[0].theta, psrs[0].phi, marker='*', s=1/(t0_max-tspan0), linewidth=2, color='xkcd:red',\n",
    "               label='Pulsars', coord=COORD)\n",
    "for p in psrs[1:]:\n",
    "    tspan = enterprise_extensions.model_utils.get_tspan([p]) / (365.25*24*3600)\n",
    "    print( tspan )\n",
    "    #if p.name=='J0613-0200':\n",
    "    #if p.name=='J1600-3053':\n",
    "    if p.name=='J1455-3330':\n",
    "    #if p.name=='J1747-4036':\n",
    "    #if p.name=='J1909-3744':\n",
    "    #if p.name==None:\n",
    "        print('yeah')\n",
    "        hp.projscatter(p.theta, p.phi, marker='*', s=1/(t0_max-tspan), linewidth=2, color='xkcd:orange', coord=COORD)\n",
    "    else:\n",
    "        hp.projscatter(p.theta, p.phi, marker='*', s=1/(t0_max-tspan), linewidth=2, color='xkcd:red', coord=COORD)\n",
    "\n",
    "#injected location\n",
    "hp.projscatter(np.pi/2, 4.0, marker=\"^\", s = 50, facecolor='none',\n",
    "              linewidth=2, color='xkcd:yellow', label='GW source', zorder=3)\n",
    "\n",
    "#spt.healpix_heatmap(skymap, cmap='PuOr', norm=norm)\n",
    "#plt.colorbar(orientation='horizontal', pad=0.05)\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "#plt.savefig(\"Results/Plots/skymap_worst_case_scenario_psr0.png\", dpi=300)\n",
    "#plt.savefig(\"Results/Plots/skymap_worst_case_scenario_orth_psr0.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gw_theta)\n",
    "plt.axhline(np.pi/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dbc346",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gw_phi)\n",
    "plt.axhline(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ac140",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9f56c6",
   "metadata": {},
   "source": [
    "# Bayesogram file to import and make all reconstructions in one line. WORK IN PROGRESS (4/13/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b8257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bayesogram_Generator as Bayesogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51205089",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_path = \"/home/reyna/BayesHopperBurst/QuickBurst/Testing/2_wavelet_sim/chain_QB_prior_10_take2.npz\" \n",
    "par_direc = '/home/reyna/BayesHopperBurst/BenceData/2_Wavelet_Sim/par/'\n",
    "tim_direc = '/home/reyna/BayesHopperBurst/BenceData/2_Wavelet_Sim/2_wavelet_tims/'\n",
    "\n",
    "\n",
    "samples, log_likelihood, acc_fraction, swap_record, psrs, parfiles, timfiles = Bayesogram.Bayesogram_init(chain_path, par_direc, tim_direc) \n",
    "                                                                    \n",
    "print(samples, log_likelihood, acc_fraction, swap_record)\n",
    "\n",
    "Bayesogram.Bayesogram(samples, log_likelihood, psrs, parfiles, timfiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
